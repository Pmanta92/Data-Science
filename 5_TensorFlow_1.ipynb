{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos las librerias basicas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#importamos las librerias de Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generamos el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Dureza</th>\n",
       "      <th>Solidos</th>\n",
       "      <th>Cloraminas</th>\n",
       "      <th>Sulfatos</th>\n",
       "      <th>Conductividad</th>\n",
       "      <th>Carbon_organico</th>\n",
       "      <th>Halogeno_metano</th>\n",
       "      <th>Turbiedad</th>\n",
       "      <th>Potabilidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890456</td>\n",
       "      <td>20791.31898</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.05786</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.54173</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.41744</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436525</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.98634</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>4.668102</td>\n",
       "      <td>193.681736</td>\n",
       "      <td>47580.99160</td>\n",
       "      <td>7.166639</td>\n",
       "      <td>359.948574</td>\n",
       "      <td>526.424171</td>\n",
       "      <td>13.894419</td>\n",
       "      <td>66.687695</td>\n",
       "      <td>4.435821</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>7.808856</td>\n",
       "      <td>193.553212</td>\n",
       "      <td>17329.80216</td>\n",
       "      <td>8.061362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>392.449580</td>\n",
       "      <td>19.903225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.798243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>9.419510</td>\n",
       "      <td>175.762646</td>\n",
       "      <td>33155.57822</td>\n",
       "      <td>7.350233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>432.044783</td>\n",
       "      <td>11.039070</td>\n",
       "      <td>69.845400</td>\n",
       "      <td>3.298875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>5.126763</td>\n",
       "      <td>230.603758</td>\n",
       "      <td>11983.86938</td>\n",
       "      <td>6.303357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>402.883113</td>\n",
       "      <td>11.168946</td>\n",
       "      <td>77.488213</td>\n",
       "      <td>4.708658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>7.874671</td>\n",
       "      <td>195.102299</td>\n",
       "      <td>17404.17706</td>\n",
       "      <td>7.509306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>327.459761</td>\n",
       "      <td>16.140368</td>\n",
       "      <td>78.698446</td>\n",
       "      <td>2.309149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3276 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ph      Dureza      Solidos  Cloraminas    Sulfatos  \\\n",
       "0          NaN  204.890456  20791.31898    7.300212  368.516441   \n",
       "1     3.716080  129.422921  18630.05786    6.635246         NaN   \n",
       "2     8.099124  224.236259  19909.54173    9.275884         NaN   \n",
       "3     8.316766  214.373394  22018.41744    8.059332  356.886136   \n",
       "4     9.092223  181.101509  17978.98634    6.546600  310.135738   \n",
       "...        ...         ...          ...         ...         ...   \n",
       "3271  4.668102  193.681736  47580.99160    7.166639  359.948574   \n",
       "3272  7.808856  193.553212  17329.80216    8.061362         NaN   \n",
       "3273  9.419510  175.762646  33155.57822    7.350233         NaN   \n",
       "3274  5.126763  230.603758  11983.86938    6.303357         NaN   \n",
       "3275  7.874671  195.102299  17404.17706    7.509306         NaN   \n",
       "\n",
       "      Conductividad  Carbon_organico  Halogeno_metano  Turbiedad  Potabilidad  \n",
       "0        564.308654        10.379783        86.990970   2.963135            0  \n",
       "1        592.885359        15.180013        56.329076   4.500656            0  \n",
       "2        418.606213        16.868637        66.420093   3.055934            0  \n",
       "3        363.266516        18.436525       100.341674   4.628771            0  \n",
       "4        398.410813        11.558279        31.997993   4.075075            0  \n",
       "...             ...              ...              ...        ...          ...  \n",
       "3271     526.424171        13.894419        66.687695   4.435821            1  \n",
       "3272     392.449580        19.903225              NaN   2.798243            1  \n",
       "3273     432.044783        11.039070        69.845400   3.298875            1  \n",
       "3274     402.883113        11.168946        77.488213   4.708658            1  \n",
       "3275     327.459761        16.140368        78.698446   2.309149            1  \n",
       "\n",
       "[3276 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = pd.read_csv(\"Datos de potabilidad_agua.csv\")\n",
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[           nan, 2.04890456e+02, 2.07913190e+04, ...,\n",
       "        1.03797831e+01, 8.69909705e+01, 2.96313538e+00],\n",
       "       [3.71608007e+00, 1.29422921e+02, 1.86300579e+04, ...,\n",
       "        1.51800131e+01, 5.63290763e+01, 4.50065627e+00],\n",
       "       [8.09912419e+00, 2.24236259e+02, 1.99095417e+04, ...,\n",
       "        1.68686369e+01, 6.64200925e+01, 3.05593375e+00],\n",
       "       ...,\n",
       "       [9.41951032e+00, 1.75762646e+02, 3.31555782e+04, ...,\n",
       "        1.10390697e+01, 6.98454003e+01, 3.29887550e+00],\n",
       "       [5.12676292e+00, 2.30603758e+02, 1.19838694e+04, ...,\n",
       "        1.11689462e+01, 7.74882131e+01, 4.70865847e+00],\n",
       "       [7.87467136e+00, 1.95102299e+02, 1.74041771e+04, ...,\n",
       "        1.61403676e+01, 7.86984463e+01, 2.30914906e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"iloc\" permite seleccionar filas y columnas por su posiciÃ³n\n",
    "# \"values\" convierte el dataframe a un array de numpy\n",
    "x = datos.iloc[:, 0:9].values # seleccionamos las columnas de 0 a 8 y las filas de 0 a 1999\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = datos.iloc[:, 9].values #separamos la variable dependiente\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imputacion de datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.08079450e+00, 2.04890456e+02, 2.07913190e+04, ...,\n",
       "        1.03797831e+01, 8.69909705e+01, 2.96313538e+00],\n",
       "       [3.71608007e+00, 1.29422921e+02, 1.86300579e+04, ...,\n",
       "        1.51800131e+01, 5.63290763e+01, 4.50065627e+00],\n",
       "       [8.09912419e+00, 2.24236259e+02, 1.99095417e+04, ...,\n",
       "        1.68686369e+01, 6.64200925e+01, 3.05593375e+00],\n",
       "       ...,\n",
       "       [9.41951032e+00, 1.75762646e+02, 3.31555782e+04, ...,\n",
       "        1.10390697e+01, 6.98454003e+01, 3.29887550e+00],\n",
       "       [5.12676292e+00, 2.30603758e+02, 1.19838694e+04, ...,\n",
       "        1.11689462e+01, 7.74882131e+01, 4.70865847e+00],\n",
       "       [7.87467136e+00, 1.95102299e+02, 1.74041771e+04, ...,\n",
       "        1.61403676e+01, 7.86984463e+01, 2.30914906e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean') #\"mean\" es la media de la columna\n",
    "imputer = imputer.fit(x[:, 0:9]) #ajustamos el imputador a los datos\n",
    "x[:, 0:9] = imputer.transform(x[:, 0:9]) #transformamos los datos\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estandarizar las escalas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  2.59194712e-01, -1.39470871e-01, ...,\n",
       "        -1.18065057e+00,  1.30614943e+00, -1.28629758e+00],\n",
       "       [-2.28933938e+00, -2.03641367e+00, -3.85986649e-01, ...,\n",
       "         2.70597241e-01, -6.38479983e-01,  6.84217891e-01],\n",
       "       [ 6.92867789e-01,  8.47664833e-01, -2.40047337e-01, ...,\n",
       "         7.81116858e-01,  1.50940874e-03, -1.16736546e+00],\n",
       "       ...,\n",
       "       [ 1.59125368e+00, -6.26829230e-01,  1.27080989e+00, ...,\n",
       "        -9.81329233e-01,  2.18748247e-01, -8.56006782e-01],\n",
       "       [-1.32951593e+00,  1.04135450e+00, -1.14405809e+00, ...,\n",
       "        -9.42063817e-01,  7.03468419e-01,  9.50797384e-01],\n",
       "       [ 5.40150905e-01, -3.85462306e-02, -5.25811938e-01, ...,\n",
       "         5.60940071e-01,  7.80223466e-01, -2.12445866e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() #creamos el objeto scaler\n",
    "scaler = scaler.fit(x) #ajustamos el scaler a los datos\n",
    "x = scaler.transform(x) #transformamos los datos\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# separamos los datos en el conjunto de entrenamiento y el conjunto\n",
    "# de prueba 80% de los datos para entrenamiento y 20% para prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0) #random_state es la semilla para la aleatoriedad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creamos el modelo de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = Sequential() #creamos el modelo secuencial\n",
    "entrada = Dense(units=9, activation='relu') #capa de entrada con 9 neuronas y funcion de activacion relu\n",
    "oculta1 = Dense(units=1000, activation='relu') #capa oculta con 50 neuronas y funcion de activacion relu\n",
    "oculta2 = Dense(units=1000, activation='relu') #capa oculta con 100 neuronas y funcion de activacion relu\n",
    "salida = Dense(units=1, activation='sigmoid') #capa de salida con 1 neurona y funcion de activacion sigmoide\n",
    "red.add(entrada) #agregamos la capa de entrada al modelo\n",
    "red.add(oculta1) #agregamos la capa oculta 1 al modelo\n",
    "red.add(oculta2) #agregamos la capa oculta 2 al modelo\n",
    "red.add(salida) #agregamos la capa de salida al modelo\n",
    "red.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), \n",
    "            loss='binary_crossentropy', \n",
    "            metrics=['accuracy']) #compilamos el modelo con el optimizador SGD y la funcion de perdida binary_crossentropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizamos el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.5526 - accuracy: 0.7114 - val_loss: 0.6357 - val_accuracy: 0.6622\n",
      "Epoch 2/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7128 - val_loss: 0.6343 - val_accuracy: 0.6565\n",
      "Epoch 3/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.7137 - val_loss: 0.6337 - val_accuracy: 0.6546\n",
      "Epoch 4/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.7090 - val_loss: 0.6322 - val_accuracy: 0.6565\n",
      "Epoch 5/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7137 - val_loss: 0.6340 - val_accuracy: 0.6546\n",
      "Epoch 6/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.7109 - val_loss: 0.6336 - val_accuracy: 0.6584\n",
      "Epoch 7/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7161 - val_loss: 0.6367 - val_accuracy: 0.6622\n",
      "Epoch 8/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7133 - val_loss: 0.6350 - val_accuracy: 0.6546\n",
      "Epoch 9/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7147 - val_loss: 0.6324 - val_accuracy: 0.6622\n",
      "Epoch 10/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7152 - val_loss: 0.6346 - val_accuracy: 0.6565\n",
      "Epoch 11/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7137 - val_loss: 0.6328 - val_accuracy: 0.6584\n",
      "Epoch 12/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.7133 - val_loss: 0.6365 - val_accuracy: 0.6603\n",
      "Epoch 13/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7147 - val_loss: 0.6356 - val_accuracy: 0.6527\n",
      "Epoch 14/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7128 - val_loss: 0.6379 - val_accuracy: 0.6622\n",
      "Epoch 15/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.7137 - val_loss: 0.6358 - val_accuracy: 0.6565\n",
      "Epoch 16/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7171 - val_loss: 0.6383 - val_accuracy: 0.6565\n",
      "Epoch 17/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7166 - val_loss: 0.6343 - val_accuracy: 0.6622\n",
      "Epoch 18/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.7180 - val_loss: 0.6345 - val_accuracy: 0.6603\n",
      "Epoch 19/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7176 - val_loss: 0.6339 - val_accuracy: 0.6584\n",
      "Epoch 20/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.7161 - val_loss: 0.6385 - val_accuracy: 0.6603\n",
      "Epoch 21/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.7156 - val_loss: 0.6391 - val_accuracy: 0.6584\n",
      "Epoch 22/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7161 - val_loss: 0.6341 - val_accuracy: 0.6622\n",
      "Epoch 23/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7161 - val_loss: 0.6356 - val_accuracy: 0.6584\n",
      "Epoch 24/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.7152 - val_loss: 0.6389 - val_accuracy: 0.6660\n",
      "Epoch 25/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7128 - val_loss: 0.6356 - val_accuracy: 0.6603\n",
      "Epoch 26/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7166 - val_loss: 0.6364 - val_accuracy: 0.6641\n",
      "Epoch 27/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.7171 - val_loss: 0.6369 - val_accuracy: 0.6641\n",
      "Epoch 28/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.7185 - val_loss: 0.6371 - val_accuracy: 0.6622\n",
      "Epoch 29/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.7214 - val_loss: 0.6366 - val_accuracy: 0.6660\n",
      "Epoch 30/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.7166 - val_loss: 0.6374 - val_accuracy: 0.6622\n",
      "Epoch 31/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.7147 - val_loss: 0.6354 - val_accuracy: 0.6603\n",
      "Epoch 32/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7152 - val_loss: 0.6356 - val_accuracy: 0.6698\n",
      "Epoch 33/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.7137 - val_loss: 0.6355 - val_accuracy: 0.6603\n",
      "Epoch 34/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7195 - val_loss: 0.6402 - val_accuracy: 0.6584\n",
      "Epoch 35/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.7195 - val_loss: 0.6387 - val_accuracy: 0.6622\n",
      "Epoch 36/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5461 - accuracy: 0.7185 - val_loss: 0.6365 - val_accuracy: 0.6584\n",
      "Epoch 37/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7152 - val_loss: 0.6355 - val_accuracy: 0.6622\n",
      "Epoch 38/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7190 - val_loss: 0.6382 - val_accuracy: 0.6622\n",
      "Epoch 39/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.7171 - val_loss: 0.6371 - val_accuracy: 0.6641\n",
      "Epoch 40/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.7142 - val_loss: 0.6368 - val_accuracy: 0.6679\n",
      "Epoch 41/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7190 - val_loss: 0.6364 - val_accuracy: 0.6660\n",
      "Epoch 42/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7209 - val_loss: 0.6379 - val_accuracy: 0.6660\n",
      "Epoch 43/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7161 - val_loss: 0.6414 - val_accuracy: 0.6698\n",
      "Epoch 44/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.7185 - val_loss: 0.6397 - val_accuracy: 0.6584\n",
      "Epoch 45/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7166 - val_loss: 0.6374 - val_accuracy: 0.6622\n",
      "Epoch 46/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7190 - val_loss: 0.6373 - val_accuracy: 0.6622\n",
      "Epoch 47/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7185 - val_loss: 0.6385 - val_accuracy: 0.6679\n",
      "Epoch 48/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7195 - val_loss: 0.6357 - val_accuracy: 0.6698\n",
      "Epoch 49/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7176 - val_loss: 0.6393 - val_accuracy: 0.6679\n",
      "Epoch 50/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7247 - val_loss: 0.6353 - val_accuracy: 0.6660\n",
      "Epoch 51/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7176 - val_loss: 0.6382 - val_accuracy: 0.6698\n",
      "Epoch 52/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7242 - val_loss: 0.6413 - val_accuracy: 0.6527\n",
      "Epoch 53/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7190 - val_loss: 0.6390 - val_accuracy: 0.6622\n",
      "Epoch 54/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.7242 - val_loss: 0.6421 - val_accuracy: 0.6508\n",
      "Epoch 55/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7228 - val_loss: 0.6431 - val_accuracy: 0.6679\n",
      "Epoch 56/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7185 - val_loss: 0.6405 - val_accuracy: 0.6622\n",
      "Epoch 57/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7199 - val_loss: 0.6383 - val_accuracy: 0.6641\n",
      "Epoch 58/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7185 - val_loss: 0.6414 - val_accuracy: 0.6679\n",
      "Epoch 59/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.7204 - val_loss: 0.6411 - val_accuracy: 0.6679\n",
      "Epoch 60/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7195 - val_loss: 0.6375 - val_accuracy: 0.6698\n",
      "Epoch 61/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5390 - accuracy: 0.7219 - val_loss: 0.6400 - val_accuracy: 0.6508\n",
      "Epoch 62/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7223 - val_loss: 0.6409 - val_accuracy: 0.6660\n",
      "Epoch 63/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7238 - val_loss: 0.6389 - val_accuracy: 0.6679\n",
      "Epoch 64/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.7247 - val_loss: 0.6388 - val_accuracy: 0.6718\n",
      "Epoch 65/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7223 - val_loss: 0.6376 - val_accuracy: 0.6698\n",
      "Epoch 66/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7261 - val_loss: 0.6420 - val_accuracy: 0.6737\n",
      "Epoch 67/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5395 - accuracy: 0.7214 - val_loss: 0.6385 - val_accuracy: 0.6698\n",
      "Epoch 68/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7223 - val_loss: 0.6375 - val_accuracy: 0.6679\n",
      "Epoch 69/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.7233 - val_loss: 0.6444 - val_accuracy: 0.6546\n",
      "Epoch 70/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7199 - val_loss: 0.6408 - val_accuracy: 0.6737\n",
      "Epoch 71/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5390 - accuracy: 0.7238 - val_loss: 0.6409 - val_accuracy: 0.6565\n",
      "Epoch 72/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7228 - val_loss: 0.6419 - val_accuracy: 0.6698\n",
      "Epoch 73/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7252 - val_loss: 0.6405 - val_accuracy: 0.6660\n",
      "Epoch 74/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7252 - val_loss: 0.6419 - val_accuracy: 0.6527\n",
      "Epoch 75/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5366 - accuracy: 0.7219 - val_loss: 0.6422 - val_accuracy: 0.6527\n",
      "Epoch 76/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7261 - val_loss: 0.6418 - val_accuracy: 0.6756\n",
      "Epoch 77/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7300 - val_loss: 0.6447 - val_accuracy: 0.6508\n",
      "Epoch 78/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7261 - val_loss: 0.6415 - val_accuracy: 0.6641\n",
      "Epoch 79/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7281 - val_loss: 0.6454 - val_accuracy: 0.6527\n",
      "Epoch 80/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7228 - val_loss: 0.6450 - val_accuracy: 0.6565\n",
      "Epoch 81/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7276 - val_loss: 0.6429 - val_accuracy: 0.6679\n",
      "Epoch 82/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7281 - val_loss: 0.6454 - val_accuracy: 0.6718\n",
      "Epoch 83/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7247 - val_loss: 0.6418 - val_accuracy: 0.6718\n",
      "Epoch 84/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7252 - val_loss: 0.6401 - val_accuracy: 0.6718\n",
      "Epoch 85/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7233 - val_loss: 0.6423 - val_accuracy: 0.6756\n",
      "Epoch 86/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7271 - val_loss: 0.6428 - val_accuracy: 0.6622\n",
      "Epoch 87/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7271 - val_loss: 0.6385 - val_accuracy: 0.6679\n",
      "Epoch 88/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7228 - val_loss: 0.6428 - val_accuracy: 0.6698\n",
      "Epoch 89/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7333 - val_loss: 0.6416 - val_accuracy: 0.6737\n",
      "Epoch 90/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.5345 - accuracy: 0.7257 - val_loss: 0.6452 - val_accuracy: 0.6508\n",
      "Epoch 91/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7271 - val_loss: 0.6415 - val_accuracy: 0.6698\n",
      "Epoch 92/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7228 - val_loss: 0.6440 - val_accuracy: 0.6718\n",
      "Epoch 93/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7285 - val_loss: 0.6498 - val_accuracy: 0.6546\n",
      "Epoch 94/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7238 - val_loss: 0.6424 - val_accuracy: 0.6641\n",
      "Epoch 95/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7252 - val_loss: 0.6462 - val_accuracy: 0.6698\n",
      "Epoch 96/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7261 - val_loss: 0.6413 - val_accuracy: 0.6641\n",
      "Epoch 97/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7343 - val_loss: 0.6430 - val_accuracy: 0.6718\n",
      "Epoch 98/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7290 - val_loss: 0.6464 - val_accuracy: 0.6603\n",
      "Epoch 99/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7271 - val_loss: 0.6450 - val_accuracy: 0.6679\n",
      "Epoch 100/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7276 - val_loss: 0.6439 - val_accuracy: 0.6679\n",
      "Epoch 101/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7333 - val_loss: 0.6475 - val_accuracy: 0.6508\n",
      "Epoch 102/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7290 - val_loss: 0.6459 - val_accuracy: 0.6718\n",
      "Epoch 103/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7261 - val_loss: 0.6493 - val_accuracy: 0.6622\n",
      "Epoch 104/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7300 - val_loss: 0.6426 - val_accuracy: 0.6698\n",
      "Epoch 105/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7309 - val_loss: 0.6427 - val_accuracy: 0.6698\n",
      "Epoch 106/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7257 - val_loss: 0.6447 - val_accuracy: 0.6679\n",
      "Epoch 107/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7309 - val_loss: 0.6444 - val_accuracy: 0.6622\n",
      "Epoch 108/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7285 - val_loss: 0.6482 - val_accuracy: 0.6737\n",
      "Epoch 109/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7323 - val_loss: 0.6459 - val_accuracy: 0.6718\n",
      "Epoch 110/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7323 - val_loss: 0.6507 - val_accuracy: 0.6679\n",
      "Epoch 111/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7352 - val_loss: 0.6430 - val_accuracy: 0.6679\n",
      "Epoch 112/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5299 - accuracy: 0.7304 - val_loss: 0.6448 - val_accuracy: 0.6698\n",
      "Epoch 113/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7323 - val_loss: 0.6472 - val_accuracy: 0.6565\n",
      "Epoch 114/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7352 - val_loss: 0.6526 - val_accuracy: 0.6641\n",
      "Epoch 115/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7347 - val_loss: 0.6434 - val_accuracy: 0.6641\n",
      "Epoch 116/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7333 - val_loss: 0.6471 - val_accuracy: 0.6641\n",
      "Epoch 117/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7271 - val_loss: 0.6527 - val_accuracy: 0.6660\n",
      "Epoch 118/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.7343 - val_loss: 0.6471 - val_accuracy: 0.6660\n",
      "Epoch 119/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7352 - val_loss: 0.6459 - val_accuracy: 0.6660\n",
      "Epoch 120/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7405 - val_loss: 0.6464 - val_accuracy: 0.6679\n",
      "Epoch 121/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7328 - val_loss: 0.6480 - val_accuracy: 0.6527\n",
      "Epoch 122/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7366 - val_loss: 0.6437 - val_accuracy: 0.6660\n",
      "Epoch 123/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7343 - val_loss: 0.6449 - val_accuracy: 0.6660\n",
      "Epoch 124/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7300 - val_loss: 0.6506 - val_accuracy: 0.6641\n",
      "Epoch 125/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7343 - val_loss: 0.6473 - val_accuracy: 0.6737\n",
      "Epoch 126/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7338 - val_loss: 0.6525 - val_accuracy: 0.6660\n",
      "Epoch 127/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7366 - val_loss: 0.6490 - val_accuracy: 0.6756\n",
      "Epoch 128/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7328 - val_loss: 0.6460 - val_accuracy: 0.6698\n",
      "Epoch 129/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7357 - val_loss: 0.6506 - val_accuracy: 0.6508\n",
      "Epoch 130/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.7362 - val_loss: 0.6510 - val_accuracy: 0.6641\n",
      "Epoch 131/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7343 - val_loss: 0.6498 - val_accuracy: 0.6622\n",
      "Epoch 132/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7333 - val_loss: 0.6469 - val_accuracy: 0.6565\n",
      "Epoch 133/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7323 - val_loss: 0.6462 - val_accuracy: 0.6584\n",
      "Epoch 134/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7357 - val_loss: 0.6483 - val_accuracy: 0.6679\n",
      "Epoch 135/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7314 - val_loss: 0.6469 - val_accuracy: 0.6565\n",
      "Epoch 136/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7338 - val_loss: 0.6455 - val_accuracy: 0.6603\n",
      "Epoch 137/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7333 - val_loss: 0.6469 - val_accuracy: 0.6622\n",
      "Epoch 138/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7376 - val_loss: 0.6487 - val_accuracy: 0.6698\n",
      "Epoch 139/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7357 - val_loss: 0.6502 - val_accuracy: 0.6489\n",
      "Epoch 140/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7366 - val_loss: 0.6500 - val_accuracy: 0.6660\n",
      "Epoch 141/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7385 - val_loss: 0.6518 - val_accuracy: 0.6469\n",
      "Epoch 142/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7438 - val_loss: 0.6518 - val_accuracy: 0.6660\n",
      "Epoch 143/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7343 - val_loss: 0.6490 - val_accuracy: 0.6698\n",
      "Epoch 144/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7400 - val_loss: 0.6495 - val_accuracy: 0.6565\n",
      "Epoch 145/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7371 - val_loss: 0.6467 - val_accuracy: 0.6565\n",
      "Epoch 146/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7357 - val_loss: 0.6534 - val_accuracy: 0.6527\n",
      "Epoch 147/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.7376 - val_loss: 0.6591 - val_accuracy: 0.6489\n",
      "Epoch 148/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.7414 - val_loss: 0.6498 - val_accuracy: 0.6546\n",
      "Epoch 149/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7462 - val_loss: 0.6498 - val_accuracy: 0.6584\n",
      "Epoch 150/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7371 - val_loss: 0.6493 - val_accuracy: 0.6546\n",
      "Epoch 151/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7366 - val_loss: 0.6600 - val_accuracy: 0.6698\n",
      "Epoch 152/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7362 - val_loss: 0.6545 - val_accuracy: 0.6718\n",
      "Epoch 153/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7390 - val_loss: 0.6515 - val_accuracy: 0.6546\n",
      "Epoch 154/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7381 - val_loss: 0.6493 - val_accuracy: 0.6603\n",
      "Epoch 155/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7376 - val_loss: 0.6542 - val_accuracy: 0.6679\n",
      "Epoch 156/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7381 - val_loss: 0.6464 - val_accuracy: 0.6641\n",
      "Epoch 157/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7390 - val_loss: 0.6509 - val_accuracy: 0.6546\n",
      "Epoch 158/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7428 - val_loss: 0.6514 - val_accuracy: 0.6622\n",
      "Epoch 159/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7385 - val_loss: 0.6483 - val_accuracy: 0.6641\n",
      "Epoch 160/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7452 - val_loss: 0.6535 - val_accuracy: 0.6603\n",
      "Epoch 161/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7405 - val_loss: 0.6542 - val_accuracy: 0.6641\n",
      "Epoch 162/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7424 - val_loss: 0.6509 - val_accuracy: 0.6546\n",
      "Epoch 163/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7409 - val_loss: 0.6492 - val_accuracy: 0.6622\n",
      "Epoch 164/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7414 - val_loss: 0.6541 - val_accuracy: 0.6546\n",
      "Epoch 165/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7428 - val_loss: 0.6539 - val_accuracy: 0.6603\n",
      "Epoch 166/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7405 - val_loss: 0.6541 - val_accuracy: 0.6660\n",
      "Epoch 167/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7385 - val_loss: 0.6566 - val_accuracy: 0.6679\n",
      "Epoch 168/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7476 - val_loss: 0.6540 - val_accuracy: 0.6660\n",
      "Epoch 169/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7438 - val_loss: 0.6548 - val_accuracy: 0.6641\n",
      "Epoch 170/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7414 - val_loss: 0.6571 - val_accuracy: 0.6584\n",
      "Epoch 171/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7419 - val_loss: 0.6612 - val_accuracy: 0.6508\n",
      "Epoch 172/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7467 - val_loss: 0.6483 - val_accuracy: 0.6622\n",
      "Epoch 173/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7414 - val_loss: 0.6562 - val_accuracy: 0.6603\n",
      "Epoch 174/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7443 - val_loss: 0.6524 - val_accuracy: 0.6603\n",
      "Epoch 175/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7476 - val_loss: 0.6599 - val_accuracy: 0.6603\n",
      "Epoch 176/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7462 - val_loss: 0.6563 - val_accuracy: 0.6641\n",
      "Epoch 177/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7448 - val_loss: 0.6584 - val_accuracy: 0.6527\n",
      "Epoch 178/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7424 - val_loss: 0.6659 - val_accuracy: 0.6546\n",
      "Epoch 179/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7514 - val_loss: 0.6640 - val_accuracy: 0.6565\n",
      "Epoch 180/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7428 - val_loss: 0.6582 - val_accuracy: 0.6622\n",
      "Epoch 181/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7495 - val_loss: 0.6549 - val_accuracy: 0.6641\n",
      "Epoch 182/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7481 - val_loss: 0.6525 - val_accuracy: 0.6622\n",
      "Epoch 183/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7490 - val_loss: 0.6490 - val_accuracy: 0.6660\n",
      "Epoch 184/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7510 - val_loss: 0.6553 - val_accuracy: 0.6679\n",
      "Epoch 185/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7524 - val_loss: 0.6549 - val_accuracy: 0.6527\n",
      "Epoch 186/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7519 - val_loss: 0.6571 - val_accuracy: 0.6565\n",
      "Epoch 187/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7448 - val_loss: 0.6622 - val_accuracy: 0.6660\n",
      "Epoch 188/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7452 - val_loss: 0.6586 - val_accuracy: 0.6489\n",
      "Epoch 189/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7524 - val_loss: 0.6637 - val_accuracy: 0.6622\n",
      "Epoch 190/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7510 - val_loss: 0.6549 - val_accuracy: 0.6622\n",
      "Epoch 191/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7538 - val_loss: 0.6548 - val_accuracy: 0.6546\n",
      "Epoch 192/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7467 - val_loss: 0.6575 - val_accuracy: 0.6565\n",
      "Epoch 193/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7471 - val_loss: 0.6530 - val_accuracy: 0.6622\n",
      "Epoch 194/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7471 - val_loss: 0.6578 - val_accuracy: 0.6622\n",
      "Epoch 195/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7500 - val_loss: 0.6595 - val_accuracy: 0.6679\n",
      "Epoch 196/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7452 - val_loss: 0.6548 - val_accuracy: 0.6660\n",
      "Epoch 197/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7510 - val_loss: 0.6610 - val_accuracy: 0.6660\n",
      "Epoch 198/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7552 - val_loss: 0.6657 - val_accuracy: 0.6698\n",
      "Epoch 199/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7476 - val_loss: 0.6624 - val_accuracy: 0.6660\n",
      "Epoch 200/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7433 - val_loss: 0.6631 - val_accuracy: 0.6641\n",
      "Epoch 201/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7481 - val_loss: 0.6613 - val_accuracy: 0.6565\n",
      "Epoch 202/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7505 - val_loss: 0.6669 - val_accuracy: 0.6508\n",
      "Epoch 203/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7548 - val_loss: 0.6725 - val_accuracy: 0.6565\n",
      "Epoch 204/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7581 - val_loss: 0.6684 - val_accuracy: 0.6489\n",
      "Epoch 205/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7543 - val_loss: 0.6725 - val_accuracy: 0.6469\n",
      "Epoch 206/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7476 - val_loss: 0.6608 - val_accuracy: 0.6489\n",
      "Epoch 207/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7557 - val_loss: 0.6607 - val_accuracy: 0.6603\n",
      "Epoch 208/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7529 - val_loss: 0.6697 - val_accuracy: 0.6412\n",
      "Epoch 209/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7591 - val_loss: 0.6632 - val_accuracy: 0.6603\n",
      "Epoch 210/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7538 - val_loss: 0.6693 - val_accuracy: 0.6527\n",
      "Epoch 211/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7524 - val_loss: 0.6702 - val_accuracy: 0.6641\n",
      "Epoch 212/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7533 - val_loss: 0.6620 - val_accuracy: 0.6508\n",
      "Epoch 213/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7562 - val_loss: 0.6560 - val_accuracy: 0.6603\n",
      "Epoch 214/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7548 - val_loss: 0.6579 - val_accuracy: 0.6584\n",
      "Epoch 215/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7529 - val_loss: 0.6568 - val_accuracy: 0.6565\n",
      "Epoch 216/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7557 - val_loss: 0.6593 - val_accuracy: 0.6737\n",
      "Epoch 217/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7557 - val_loss: 0.6640 - val_accuracy: 0.6546\n",
      "Epoch 218/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7567 - val_loss: 0.6645 - val_accuracy: 0.6489\n",
      "Epoch 219/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7576 - val_loss: 0.6753 - val_accuracy: 0.6336\n",
      "Epoch 220/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7557 - val_loss: 0.6688 - val_accuracy: 0.6603\n",
      "Epoch 221/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7505 - val_loss: 0.6650 - val_accuracy: 0.6565\n",
      "Epoch 222/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7591 - val_loss: 0.6686 - val_accuracy: 0.6565\n",
      "Epoch 223/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7600 - val_loss: 0.6646 - val_accuracy: 0.6565\n",
      "Epoch 224/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7562 - val_loss: 0.6664 - val_accuracy: 0.6469\n",
      "Epoch 225/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7634 - val_loss: 0.6617 - val_accuracy: 0.6603\n",
      "Epoch 226/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7615 - val_loss: 0.6740 - val_accuracy: 0.6450\n",
      "Epoch 227/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7615 - val_loss: 0.6676 - val_accuracy: 0.6546\n",
      "Epoch 228/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7638 - val_loss: 0.6690 - val_accuracy: 0.6546\n",
      "Epoch 229/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7538 - val_loss: 0.6831 - val_accuracy: 0.6412\n",
      "Epoch 230/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7576 - val_loss: 0.6694 - val_accuracy: 0.6508\n",
      "Epoch 231/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7567 - val_loss: 0.6598 - val_accuracy: 0.6565\n",
      "Epoch 232/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7686 - val_loss: 0.6740 - val_accuracy: 0.6508\n",
      "Epoch 233/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7567 - val_loss: 0.6783 - val_accuracy: 0.6622\n",
      "Epoch 234/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7557 - val_loss: 0.6728 - val_accuracy: 0.6469\n",
      "Epoch 235/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7605 - val_loss: 0.6658 - val_accuracy: 0.6489\n",
      "Epoch 236/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7567 - val_loss: 0.6741 - val_accuracy: 0.6489\n",
      "Epoch 237/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7586 - val_loss: 0.6772 - val_accuracy: 0.6603\n",
      "Epoch 238/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.7619 - val_loss: 0.6665 - val_accuracy: 0.6546\n",
      "Epoch 239/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7638 - val_loss: 0.6714 - val_accuracy: 0.6622\n",
      "Epoch 240/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7686 - val_loss: 0.6651 - val_accuracy: 0.6565\n",
      "Epoch 241/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7653 - val_loss: 0.6680 - val_accuracy: 0.6584\n",
      "Epoch 242/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7653 - val_loss: 0.6636 - val_accuracy: 0.6698\n",
      "Epoch 243/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7586 - val_loss: 0.6698 - val_accuracy: 0.6584\n",
      "Epoch 244/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7648 - val_loss: 0.6669 - val_accuracy: 0.6489\n",
      "Epoch 245/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7557 - val_loss: 0.6702 - val_accuracy: 0.6508\n",
      "Epoch 246/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7653 - val_loss: 0.6687 - val_accuracy: 0.6546\n",
      "Epoch 247/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7700 - val_loss: 0.6688 - val_accuracy: 0.6508\n",
      "Epoch 248/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7767 - val_loss: 0.6844 - val_accuracy: 0.6393\n",
      "Epoch 249/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7710 - val_loss: 0.6755 - val_accuracy: 0.6603\n",
      "Epoch 250/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7724 - val_loss: 0.6686 - val_accuracy: 0.6679\n",
      "Epoch 251/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7595 - val_loss: 0.6892 - val_accuracy: 0.6565\n",
      "Epoch 252/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7629 - val_loss: 0.6729 - val_accuracy: 0.6508\n",
      "Epoch 253/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7605 - val_loss: 0.6818 - val_accuracy: 0.6202\n",
      "Epoch 254/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7667 - val_loss: 0.6707 - val_accuracy: 0.6565\n",
      "Epoch 255/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7758 - val_loss: 0.6801 - val_accuracy: 0.6450\n",
      "Epoch 256/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7719 - val_loss: 0.6826 - val_accuracy: 0.6450\n",
      "Epoch 257/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7672 - val_loss: 0.6708 - val_accuracy: 0.6527\n",
      "Epoch 258/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7643 - val_loss: 0.6807 - val_accuracy: 0.6393\n",
      "Epoch 259/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7662 - val_loss: 0.6706 - val_accuracy: 0.6584\n",
      "Epoch 260/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7572 - val_loss: 0.6721 - val_accuracy: 0.6508\n",
      "Epoch 261/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7653 - val_loss: 0.6708 - val_accuracy: 0.6584\n",
      "Epoch 262/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7657 - val_loss: 0.6852 - val_accuracy: 0.6355\n",
      "Epoch 263/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7796 - val_loss: 0.6911 - val_accuracy: 0.6546\n",
      "Epoch 264/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7739 - val_loss: 0.6734 - val_accuracy: 0.6584\n",
      "Epoch 265/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7719 - val_loss: 0.6749 - val_accuracy: 0.6489\n",
      "Epoch 266/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7700 - val_loss: 0.6989 - val_accuracy: 0.6298\n",
      "Epoch 267/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7677 - val_loss: 0.6790 - val_accuracy: 0.6546\n",
      "Epoch 268/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7719 - val_loss: 0.6697 - val_accuracy: 0.6660\n",
      "Epoch 269/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7657 - val_loss: 0.6764 - val_accuracy: 0.6546\n",
      "Epoch 270/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7724 - val_loss: 0.6835 - val_accuracy: 0.6355\n",
      "Epoch 271/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7772 - val_loss: 0.7007 - val_accuracy: 0.6279\n",
      "Epoch 272/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7796 - val_loss: 0.6780 - val_accuracy: 0.6565\n",
      "Epoch 273/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7715 - val_loss: 0.6889 - val_accuracy: 0.6450\n",
      "Epoch 274/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7739 - val_loss: 0.6809 - val_accuracy: 0.6641\n",
      "Epoch 275/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7705 - val_loss: 0.6903 - val_accuracy: 0.6450\n",
      "Epoch 276/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7724 - val_loss: 0.6907 - val_accuracy: 0.6508\n",
      "Epoch 277/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7810 - val_loss: 0.6803 - val_accuracy: 0.6527\n",
      "Epoch 278/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7739 - val_loss: 0.6714 - val_accuracy: 0.6584\n",
      "Epoch 279/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7715 - val_loss: 0.6851 - val_accuracy: 0.6393\n",
      "Epoch 280/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7844 - val_loss: 0.6943 - val_accuracy: 0.6412\n",
      "Epoch 281/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7700 - val_loss: 0.6819 - val_accuracy: 0.6546\n",
      "Epoch 282/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7762 - val_loss: 0.6852 - val_accuracy: 0.6489\n",
      "Epoch 283/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7786 - val_loss: 0.6828 - val_accuracy: 0.6603\n",
      "Epoch 284/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7767 - val_loss: 0.7032 - val_accuracy: 0.6374\n",
      "Epoch 285/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7824 - val_loss: 0.6868 - val_accuracy: 0.6641\n",
      "Epoch 286/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7777 - val_loss: 0.6902 - val_accuracy: 0.6450\n",
      "Epoch 287/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7796 - val_loss: 0.7065 - val_accuracy: 0.6489\n",
      "Epoch 288/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7801 - val_loss: 0.6874 - val_accuracy: 0.6527\n",
      "Epoch 289/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7739 - val_loss: 0.6933 - val_accuracy: 0.6546\n",
      "Epoch 290/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7729 - val_loss: 0.6783 - val_accuracy: 0.6584\n",
      "Epoch 291/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7796 - val_loss: 0.7052 - val_accuracy: 0.6336\n",
      "Epoch 292/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7739 - val_loss: 0.6860 - val_accuracy: 0.6641\n",
      "Epoch 293/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7805 - val_loss: 0.7222 - val_accuracy: 0.6279\n",
      "Epoch 294/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7829 - val_loss: 0.6871 - val_accuracy: 0.6489\n",
      "Epoch 295/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7824 - val_loss: 0.7036 - val_accuracy: 0.6355\n",
      "Epoch 296/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7767 - val_loss: 0.6865 - val_accuracy: 0.6737\n",
      "Epoch 297/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7786 - val_loss: 0.6987 - val_accuracy: 0.6374\n",
      "Epoch 298/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7834 - val_loss: 0.6944 - val_accuracy: 0.6527\n",
      "Epoch 299/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7810 - val_loss: 0.7054 - val_accuracy: 0.6450\n",
      "Epoch 300/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7724 - val_loss: 0.6836 - val_accuracy: 0.6431\n",
      "Epoch 301/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7791 - val_loss: 0.6922 - val_accuracy: 0.6603\n",
      "Epoch 302/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7801 - val_loss: 0.7063 - val_accuracy: 0.6412\n",
      "Epoch 303/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7829 - val_loss: 0.7122 - val_accuracy: 0.6260\n",
      "Epoch 304/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7863 - val_loss: 0.7229 - val_accuracy: 0.6393\n",
      "Epoch 305/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7844 - val_loss: 0.6912 - val_accuracy: 0.6565\n",
      "Epoch 306/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7767 - val_loss: 0.6984 - val_accuracy: 0.6431\n",
      "Epoch 307/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7910 - val_loss: 0.6902 - val_accuracy: 0.6660\n",
      "Epoch 308/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7824 - val_loss: 0.7084 - val_accuracy: 0.6431\n",
      "Epoch 309/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7834 - val_loss: 0.6953 - val_accuracy: 0.6450\n",
      "Epoch 310/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7858 - val_loss: 0.6987 - val_accuracy: 0.6431\n",
      "Epoch 311/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7886 - val_loss: 0.7202 - val_accuracy: 0.6202\n",
      "Epoch 312/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7853 - val_loss: 0.6975 - val_accuracy: 0.6412\n",
      "Epoch 313/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7886 - val_loss: 0.6974 - val_accuracy: 0.6489\n",
      "Epoch 314/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7925 - val_loss: 0.6941 - val_accuracy: 0.6393\n",
      "Epoch 315/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7786 - val_loss: 0.6949 - val_accuracy: 0.6660\n",
      "Epoch 316/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7858 - val_loss: 0.7060 - val_accuracy: 0.6508\n",
      "Epoch 317/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7886 - val_loss: 0.6954 - val_accuracy: 0.6450\n",
      "Epoch 318/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7839 - val_loss: 0.6929 - val_accuracy: 0.6450\n",
      "Epoch 319/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7839 - val_loss: 0.7278 - val_accuracy: 0.6355\n",
      "Epoch 320/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7863 - val_loss: 0.6990 - val_accuracy: 0.6431\n",
      "Epoch 321/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7968 - val_loss: 0.7101 - val_accuracy: 0.6393\n",
      "Epoch 322/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7829 - val_loss: 0.6996 - val_accuracy: 0.6527\n",
      "Epoch 323/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7896 - val_loss: 0.7156 - val_accuracy: 0.6393\n",
      "Epoch 324/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7977 - val_loss: 0.7089 - val_accuracy: 0.6374\n",
      "Epoch 325/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7867 - val_loss: 0.6937 - val_accuracy: 0.6546\n",
      "Epoch 326/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7891 - val_loss: 0.7070 - val_accuracy: 0.6336\n",
      "Epoch 327/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7948 - val_loss: 0.7292 - val_accuracy: 0.6489\n",
      "Epoch 328/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7891 - val_loss: 0.7112 - val_accuracy: 0.6565\n",
      "Epoch 329/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.8001 - val_loss: 0.7118 - val_accuracy: 0.6450\n",
      "Epoch 330/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7867 - val_loss: 0.7110 - val_accuracy: 0.6527\n",
      "Epoch 331/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7958 - val_loss: 0.7275 - val_accuracy: 0.6279\n",
      "Epoch 332/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7882 - val_loss: 0.7320 - val_accuracy: 0.6317\n",
      "Epoch 333/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7867 - val_loss: 0.7008 - val_accuracy: 0.6374\n",
      "Epoch 334/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7872 - val_loss: 0.7174 - val_accuracy: 0.6469\n",
      "Epoch 335/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7920 - val_loss: 0.6989 - val_accuracy: 0.6584\n",
      "Epoch 336/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7963 - val_loss: 0.7086 - val_accuracy: 0.6412\n",
      "Epoch 337/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7891 - val_loss: 0.7213 - val_accuracy: 0.6240\n",
      "Epoch 338/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7925 - val_loss: 0.7364 - val_accuracy: 0.6450\n",
      "Epoch 339/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7886 - val_loss: 0.7098 - val_accuracy: 0.6565\n",
      "Epoch 340/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7824 - val_loss: 0.7186 - val_accuracy: 0.6317\n",
      "Epoch 341/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7910 - val_loss: 0.7386 - val_accuracy: 0.6355\n",
      "Epoch 342/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.8001 - val_loss: 0.7190 - val_accuracy: 0.6336\n",
      "Epoch 343/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.8030 - val_loss: 0.7402 - val_accuracy: 0.6412\n",
      "Epoch 344/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7920 - val_loss: 0.7156 - val_accuracy: 0.6336\n",
      "Epoch 345/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7891 - val_loss: 0.7135 - val_accuracy: 0.6355\n",
      "Epoch 346/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7925 - val_loss: 0.7121 - val_accuracy: 0.6450\n",
      "Epoch 347/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7972 - val_loss: 0.7228 - val_accuracy: 0.6450\n",
      "Epoch 348/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7939 - val_loss: 0.7142 - val_accuracy: 0.6469\n",
      "Epoch 349/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7867 - val_loss: 0.7369 - val_accuracy: 0.6298\n",
      "Epoch 350/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7906 - val_loss: 0.7323 - val_accuracy: 0.6221\n",
      "Epoch 351/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.8001 - val_loss: 0.7210 - val_accuracy: 0.6508\n",
      "Epoch 352/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7953 - val_loss: 0.7255 - val_accuracy: 0.6355\n",
      "Epoch 353/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7977 - val_loss: 0.7206 - val_accuracy: 0.6450\n",
      "Epoch 354/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7968 - val_loss: 0.7589 - val_accuracy: 0.6298\n",
      "Epoch 355/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7982 - val_loss: 0.7232 - val_accuracy: 0.6221\n",
      "Epoch 356/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8015 - val_loss: 0.7110 - val_accuracy: 0.6546\n",
      "Epoch 357/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7991 - val_loss: 0.7207 - val_accuracy: 0.6584\n",
      "Epoch 358/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7953 - val_loss: 0.7287 - val_accuracy: 0.6393\n",
      "Epoch 359/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7953 - val_loss: 0.7507 - val_accuracy: 0.6317\n",
      "Epoch 360/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7929 - val_loss: 0.7185 - val_accuracy: 0.6393\n",
      "Epoch 361/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.8010 - val_loss: 0.7232 - val_accuracy: 0.6469\n",
      "Epoch 362/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7968 - val_loss: 0.7711 - val_accuracy: 0.6260\n",
      "Epoch 363/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8096 - val_loss: 0.7360 - val_accuracy: 0.6431\n",
      "Epoch 364/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7982 - val_loss: 0.7435 - val_accuracy: 0.6393\n",
      "Epoch 365/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.8025 - val_loss: 0.7347 - val_accuracy: 0.6336\n",
      "Epoch 366/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7944 - val_loss: 0.7499 - val_accuracy: 0.6393\n",
      "Epoch 367/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.8001 - val_loss: 0.7146 - val_accuracy: 0.6489\n",
      "Epoch 368/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7963 - val_loss: 0.7393 - val_accuracy: 0.6374\n",
      "Epoch 369/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8034 - val_loss: 0.7296 - val_accuracy: 0.6393\n",
      "Epoch 370/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.8130 - val_loss: 0.7592 - val_accuracy: 0.6355\n",
      "Epoch 371/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7958 - val_loss: 0.7336 - val_accuracy: 0.6355\n",
      "Epoch 372/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8068 - val_loss: 0.7491 - val_accuracy: 0.6240\n",
      "Epoch 373/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7953 - val_loss: 0.7316 - val_accuracy: 0.6298\n",
      "Epoch 374/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7987 - val_loss: 0.7366 - val_accuracy: 0.6393\n",
      "Epoch 375/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7944 - val_loss: 0.7453 - val_accuracy: 0.6183\n",
      "Epoch 376/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8015 - val_loss: 0.7354 - val_accuracy: 0.6374\n",
      "Epoch 377/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8025 - val_loss: 0.7334 - val_accuracy: 0.6374\n",
      "Epoch 378/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8082 - val_loss: 0.7685 - val_accuracy: 0.6260\n",
      "Epoch 379/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8025 - val_loss: 0.7967 - val_accuracy: 0.6145\n",
      "Epoch 380/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7996 - val_loss: 0.7593 - val_accuracy: 0.6317\n",
      "Epoch 381/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7968 - val_loss: 0.7444 - val_accuracy: 0.6088\n",
      "Epoch 382/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8030 - val_loss: 0.7700 - val_accuracy: 0.6183\n",
      "Epoch 383/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8053 - val_loss: 0.7592 - val_accuracy: 0.6393\n",
      "Epoch 384/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8039 - val_loss: 0.7392 - val_accuracy: 0.6527\n",
      "Epoch 385/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8044 - val_loss: 0.7333 - val_accuracy: 0.6412\n",
      "Epoch 386/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8068 - val_loss: 0.7365 - val_accuracy: 0.6317\n",
      "Epoch 387/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8101 - val_loss: 0.7484 - val_accuracy: 0.6412\n",
      "Epoch 388/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8044 - val_loss: 0.7536 - val_accuracy: 0.6317\n",
      "Epoch 389/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8030 - val_loss: 0.7401 - val_accuracy: 0.6431\n",
      "Epoch 390/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8087 - val_loss: 0.7778 - val_accuracy: 0.6279\n",
      "Epoch 391/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8030 - val_loss: 0.7527 - val_accuracy: 0.6355\n",
      "Epoch 392/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8130 - val_loss: 0.7601 - val_accuracy: 0.6317\n",
      "Epoch 393/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8144 - val_loss: 0.7732 - val_accuracy: 0.6260\n",
      "Epoch 394/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.7991 - val_loss: 0.8066 - val_accuracy: 0.6011\n",
      "Epoch 395/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8158 - val_loss: 0.7676 - val_accuracy: 0.6279\n",
      "Epoch 396/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8120 - val_loss: 0.7746 - val_accuracy: 0.6202\n",
      "Epoch 397/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8096 - val_loss: 0.7684 - val_accuracy: 0.6298\n",
      "Epoch 398/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8077 - val_loss: 0.7612 - val_accuracy: 0.6355\n",
      "Epoch 399/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8182 - val_loss: 0.7439 - val_accuracy: 0.6450\n",
      "Epoch 400/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8006 - val_loss: 0.7683 - val_accuracy: 0.6317\n",
      "Epoch 401/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8020 - val_loss: 0.7586 - val_accuracy: 0.6260\n",
      "Epoch 402/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8149 - val_loss: 0.7428 - val_accuracy: 0.6431\n",
      "Epoch 403/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8115 - val_loss: 0.7615 - val_accuracy: 0.6145\n",
      "Epoch 404/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8106 - val_loss: 0.7818 - val_accuracy: 0.6279\n",
      "Epoch 405/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7934 - val_loss: 0.7726 - val_accuracy: 0.6393\n",
      "Epoch 406/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8130 - val_loss: 0.7572 - val_accuracy: 0.6145\n",
      "Epoch 407/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8063 - val_loss: 0.7773 - val_accuracy: 0.6183\n",
      "Epoch 408/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8058 - val_loss: 0.7714 - val_accuracy: 0.6088\n",
      "Epoch 409/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8130 - val_loss: 0.7668 - val_accuracy: 0.6260\n",
      "Epoch 410/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8101 - val_loss: 0.7677 - val_accuracy: 0.6412\n",
      "Epoch 411/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8096 - val_loss: 0.7819 - val_accuracy: 0.6374\n",
      "Epoch 412/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8125 - val_loss: 0.7734 - val_accuracy: 0.6317\n",
      "Epoch 413/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8015 - val_loss: 0.7789 - val_accuracy: 0.6279\n",
      "Epoch 414/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8163 - val_loss: 0.8117 - val_accuracy: 0.6298\n",
      "Epoch 415/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8254 - val_loss: 0.7748 - val_accuracy: 0.6450\n",
      "Epoch 416/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8130 - val_loss: 0.7931 - val_accuracy: 0.6260\n",
      "Epoch 417/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8154 - val_loss: 0.7614 - val_accuracy: 0.6317\n",
      "Epoch 418/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8173 - val_loss: 0.7540 - val_accuracy: 0.6145\n",
      "Epoch 419/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8115 - val_loss: 0.8127 - val_accuracy: 0.6279\n",
      "Epoch 420/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8087 - val_loss: 0.7437 - val_accuracy: 0.6145\n",
      "Epoch 421/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.7812 - val_accuracy: 0.6317\n",
      "Epoch 422/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8144 - val_loss: 0.7911 - val_accuracy: 0.6336\n",
      "Epoch 423/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8182 - val_loss: 0.7649 - val_accuracy: 0.6450\n",
      "Epoch 424/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8197 - val_loss: 0.9864 - val_accuracy: 0.5420\n",
      "Epoch 425/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8187 - val_loss: 0.7839 - val_accuracy: 0.6088\n",
      "Epoch 426/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8135 - val_loss: 0.7662 - val_accuracy: 0.6298\n",
      "Epoch 427/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8206 - val_loss: 0.8619 - val_accuracy: 0.5763\n",
      "Epoch 428/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8192 - val_loss: 0.9149 - val_accuracy: 0.5744\n",
      "Epoch 429/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8096 - val_loss: 0.7814 - val_accuracy: 0.6412\n",
      "Epoch 430/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8158 - val_loss: 0.7889 - val_accuracy: 0.6164\n",
      "Epoch 431/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8149 - val_loss: 0.7675 - val_accuracy: 0.6240\n",
      "Epoch 432/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8120 - val_loss: 0.7862 - val_accuracy: 0.6164\n",
      "Epoch 433/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8106 - val_loss: 0.7747 - val_accuracy: 0.6336\n",
      "Epoch 434/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8216 - val_loss: 0.8093 - val_accuracy: 0.6202\n",
      "Epoch 435/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8292 - val_loss: 0.7751 - val_accuracy: 0.6221\n",
      "Epoch 436/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8163 - val_loss: 0.8448 - val_accuracy: 0.6221\n",
      "Epoch 437/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8220 - val_loss: 0.7958 - val_accuracy: 0.6374\n",
      "Epoch 438/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8154 - val_loss: 0.9068 - val_accuracy: 0.5630\n",
      "Epoch 439/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8201 - val_loss: 0.7961 - val_accuracy: 0.6336\n",
      "Epoch 440/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8182 - val_loss: 0.7592 - val_accuracy: 0.6298\n",
      "Epoch 441/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8182 - val_loss: 0.7758 - val_accuracy: 0.6221\n",
      "Epoch 442/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8125 - val_loss: 0.8256 - val_accuracy: 0.6107\n",
      "Epoch 443/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8220 - val_loss: 0.8968 - val_accuracy: 0.5744\n",
      "Epoch 444/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8115 - val_loss: 0.7866 - val_accuracy: 0.6145\n",
      "Epoch 445/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8144 - val_loss: 0.8311 - val_accuracy: 0.6374\n",
      "Epoch 446/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8106 - val_loss: 0.9125 - val_accuracy: 0.6107\n",
      "Epoch 447/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8115 - val_loss: 0.8723 - val_accuracy: 0.5954\n",
      "Epoch 448/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8163 - val_loss: 0.7987 - val_accuracy: 0.6355\n",
      "Epoch 449/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8111 - val_loss: 0.8007 - val_accuracy: 0.6393\n",
      "Epoch 450/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8168 - val_loss: 0.8169 - val_accuracy: 0.6240\n",
      "Epoch 451/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8235 - val_loss: 0.8089 - val_accuracy: 0.6584\n",
      "Epoch 452/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8173 - val_loss: 0.7805 - val_accuracy: 0.6183\n",
      "Epoch 453/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8154 - val_loss: 0.8415 - val_accuracy: 0.6221\n",
      "Epoch 454/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8168 - val_loss: 0.7690 - val_accuracy: 0.6336\n",
      "Epoch 455/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8135 - val_loss: 0.8061 - val_accuracy: 0.6279\n",
      "Epoch 456/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8087 - val_loss: 0.8126 - val_accuracy: 0.6240\n",
      "Epoch 457/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.8254 - val_loss: 0.8171 - val_accuracy: 0.6279\n",
      "Epoch 458/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8187 - val_loss: 0.9402 - val_accuracy: 0.5763\n",
      "Epoch 459/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8168 - val_loss: 0.8212 - val_accuracy: 0.6317\n",
      "Epoch 460/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8240 - val_loss: 0.7904 - val_accuracy: 0.6279\n",
      "Epoch 461/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8158 - val_loss: 0.8217 - val_accuracy: 0.5954\n",
      "Epoch 462/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8225 - val_loss: 0.7874 - val_accuracy: 0.6260\n",
      "Epoch 463/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8282 - val_loss: 0.8146 - val_accuracy: 0.6031\n",
      "Epoch 464/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3800 - accuracy: 0.8287 - val_loss: 0.9646 - val_accuracy: 0.5725\n",
      "Epoch 465/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8211 - val_loss: 0.8218 - val_accuracy: 0.6031\n",
      "Epoch 466/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8216 - val_loss: 0.8433 - val_accuracy: 0.6527\n",
      "Epoch 467/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3884 - accuracy: 0.8263 - val_loss: 0.7940 - val_accuracy: 0.6221\n",
      "Epoch 468/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8292 - val_loss: 0.8072 - val_accuracy: 0.6221\n",
      "Epoch 469/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8282 - val_loss: 0.8167 - val_accuracy: 0.6031\n",
      "Epoch 470/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3763 - accuracy: 0.8306 - val_loss: 0.7975 - val_accuracy: 0.6107\n",
      "Epoch 471/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3774 - accuracy: 0.8325 - val_loss: 0.8323 - val_accuracy: 0.6126\n",
      "Epoch 472/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8182 - val_loss: 0.8117 - val_accuracy: 0.6107\n",
      "Epoch 473/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8120 - val_loss: 0.8261 - val_accuracy: 0.6088\n",
      "Epoch 474/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.3782 - accuracy: 0.8373 - val_loss: 0.9455 - val_accuracy: 0.5744\n",
      "Epoch 475/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8206 - val_loss: 0.8268 - val_accuracy: 0.6279\n",
      "Epoch 476/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3737 - accuracy: 0.8297 - val_loss: 0.8241 - val_accuracy: 0.6126\n",
      "Epoch 477/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.3816 - accuracy: 0.8197 - val_loss: 0.8019 - val_accuracy: 0.6317\n",
      "Epoch 478/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3800 - accuracy: 0.8278 - val_loss: 0.8602 - val_accuracy: 0.6164\n",
      "Epoch 479/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8144 - val_loss: 0.8133 - val_accuracy: 0.6183\n",
      "Epoch 480/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8311 - val_loss: 0.8429 - val_accuracy: 0.6126\n",
      "Epoch 481/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3735 - accuracy: 0.8335 - val_loss: 0.7967 - val_accuracy: 0.6145\n",
      "Epoch 482/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8311 - val_loss: 0.8340 - val_accuracy: 0.6126\n",
      "Epoch 483/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3681 - accuracy: 0.8387 - val_loss: 0.8661 - val_accuracy: 0.6031\n",
      "Epoch 484/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.8268 - val_loss: 0.8133 - val_accuracy: 0.6317\n",
      "Epoch 485/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3719 - accuracy: 0.8349 - val_loss: 0.8536 - val_accuracy: 0.6107\n",
      "Epoch 486/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8163 - val_loss: 0.8721 - val_accuracy: 0.6126\n",
      "Epoch 487/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8225 - val_loss: 0.9050 - val_accuracy: 0.6221\n",
      "Epoch 488/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8182 - val_loss: 0.8718 - val_accuracy: 0.6260\n",
      "Epoch 489/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3781 - accuracy: 0.8287 - val_loss: 0.8118 - val_accuracy: 0.6011\n",
      "Epoch 490/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3712 - accuracy: 0.8344 - val_loss: 0.8221 - val_accuracy: 0.6202\n",
      "Epoch 491/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3829 - accuracy: 0.8201 - val_loss: 0.8471 - val_accuracy: 0.6393\n",
      "Epoch 492/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.8158 - val_loss: 0.7992 - val_accuracy: 0.6279\n",
      "Epoch 493/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.8325 - val_loss: 0.8241 - val_accuracy: 0.6355\n",
      "Epoch 494/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.8273 - val_loss: 0.9232 - val_accuracy: 0.5744\n",
      "Epoch 495/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3628 - accuracy: 0.8402 - val_loss: 0.8683 - val_accuracy: 0.6202\n",
      "Epoch 496/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.8330 - val_loss: 0.8862 - val_accuracy: 0.6183\n",
      "Epoch 497/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3821 - accuracy: 0.8321 - val_loss: 0.8539 - val_accuracy: 0.6107\n",
      "Epoch 498/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.8440 - val_loss: 0.8457 - val_accuracy: 0.6240\n",
      "Epoch 499/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3775 - accuracy: 0.8311 - val_loss: 0.8511 - val_accuracy: 0.6202\n",
      "Epoch 500/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8263 - val_loss: 0.8407 - val_accuracy: 0.6336\n",
      "Epoch 501/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.8268 - val_loss: 0.8277 - val_accuracy: 0.6317\n",
      "Epoch 502/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3731 - accuracy: 0.8340 - val_loss: 0.8318 - val_accuracy: 0.6164\n",
      "Epoch 503/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8302 - val_loss: 0.8833 - val_accuracy: 0.6260\n",
      "Epoch 504/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3769 - accuracy: 0.8220 - val_loss: 0.8382 - val_accuracy: 0.6469\n",
      "Epoch 505/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8449 - val_loss: 0.9328 - val_accuracy: 0.5897\n",
      "Epoch 506/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3672 - accuracy: 0.8402 - val_loss: 0.8659 - val_accuracy: 0.6050\n",
      "Epoch 507/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3714 - accuracy: 0.8259 - val_loss: 0.8507 - val_accuracy: 0.6107\n",
      "Epoch 508/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.8392 - val_loss: 0.8537 - val_accuracy: 0.6279\n",
      "Epoch 509/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3781 - accuracy: 0.8306 - val_loss: 0.8257 - val_accuracy: 0.6374\n",
      "Epoch 510/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3747 - accuracy: 0.8321 - val_loss: 0.8648 - val_accuracy: 0.6183\n",
      "Epoch 511/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3607 - accuracy: 0.8392 - val_loss: 0.8846 - val_accuracy: 0.5973\n",
      "Epoch 512/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3718 - accuracy: 0.8316 - val_loss: 0.8485 - val_accuracy: 0.6336\n",
      "Epoch 513/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3630 - accuracy: 0.8282 - val_loss: 0.8414 - val_accuracy: 0.6298\n",
      "Epoch 514/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.8378 - val_loss: 0.8507 - val_accuracy: 0.6107\n",
      "Epoch 515/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3677 - accuracy: 0.8330 - val_loss: 0.8548 - val_accuracy: 0.6088\n",
      "Epoch 516/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3763 - accuracy: 0.8306 - val_loss: 0.8857 - val_accuracy: 0.6164\n",
      "Epoch 517/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3622 - accuracy: 0.8383 - val_loss: 0.8561 - val_accuracy: 0.6240\n",
      "Epoch 518/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8297 - val_loss: 0.9019 - val_accuracy: 0.6393\n",
      "Epoch 519/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8297 - val_loss: 0.8794 - val_accuracy: 0.6107\n",
      "Epoch 520/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8278 - val_loss: 0.8595 - val_accuracy: 0.6508\n",
      "Epoch 521/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3605 - accuracy: 0.8340 - val_loss: 0.8812 - val_accuracy: 0.6298\n",
      "Epoch 522/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3515 - accuracy: 0.8397 - val_loss: 0.8554 - val_accuracy: 0.6011\n",
      "Epoch 523/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3529 - accuracy: 0.8478 - val_loss: 0.8791 - val_accuracy: 0.6164\n",
      "Epoch 524/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8354 - val_loss: 0.8982 - val_accuracy: 0.6260\n",
      "Epoch 525/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3654 - accuracy: 0.8311 - val_loss: 0.8508 - val_accuracy: 0.6088\n",
      "Epoch 526/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3673 - accuracy: 0.8321 - val_loss: 0.8790 - val_accuracy: 0.6450\n",
      "Epoch 527/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3568 - accuracy: 0.8440 - val_loss: 1.0583 - val_accuracy: 0.6260\n",
      "Epoch 528/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.8435 - val_loss: 0.9217 - val_accuracy: 0.6202\n",
      "Epoch 529/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3669 - accuracy: 0.8316 - val_loss: 0.8704 - val_accuracy: 0.6240\n",
      "Epoch 530/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3548 - accuracy: 0.8392 - val_loss: 0.9763 - val_accuracy: 0.6107\n",
      "Epoch 531/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8282 - val_loss: 0.8765 - val_accuracy: 0.6393\n",
      "Epoch 532/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.8511 - val_loss: 0.9927 - val_accuracy: 0.5744\n",
      "Epoch 533/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3669 - accuracy: 0.8302 - val_loss: 0.8886 - val_accuracy: 0.6011\n",
      "Epoch 534/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8406 - val_loss: 0.8671 - val_accuracy: 0.6279\n",
      "Epoch 535/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3581 - accuracy: 0.8373 - val_loss: 0.8931 - val_accuracy: 0.6202\n",
      "Epoch 536/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3642 - accuracy: 0.8416 - val_loss: 0.8607 - val_accuracy: 0.6469\n",
      "Epoch 537/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3688 - accuracy: 0.8430 - val_loss: 0.8790 - val_accuracy: 0.6202\n",
      "Epoch 538/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3656 - accuracy: 0.8321 - val_loss: 0.8714 - val_accuracy: 0.6240\n",
      "Epoch 539/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3690 - accuracy: 0.8311 - val_loss: 0.8637 - val_accuracy: 0.6298\n",
      "Epoch 540/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.8435 - val_loss: 0.9938 - val_accuracy: 0.6221\n",
      "Epoch 541/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3524 - accuracy: 0.8387 - val_loss: 0.8851 - val_accuracy: 0.5954\n",
      "Epoch 542/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3529 - accuracy: 0.8402 - val_loss: 0.9869 - val_accuracy: 0.5859\n",
      "Epoch 543/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3656 - accuracy: 0.8340 - val_loss: 1.0029 - val_accuracy: 0.5630\n",
      "Epoch 544/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3512 - accuracy: 0.8478 - val_loss: 0.8959 - val_accuracy: 0.6126\n",
      "Epoch 545/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.8392 - val_loss: 0.9016 - val_accuracy: 0.6298\n",
      "Epoch 546/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8478 - val_loss: 0.8520 - val_accuracy: 0.6202\n",
      "Epoch 547/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8531 - val_loss: 0.9825 - val_accuracy: 0.5840\n",
      "Epoch 548/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8483 - val_loss: 1.3263 - val_accuracy: 0.5267\n",
      "Epoch 549/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3767 - accuracy: 0.8297 - val_loss: 0.8835 - val_accuracy: 0.6317\n",
      "Epoch 550/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3714 - accuracy: 0.8297 - val_loss: 0.9143 - val_accuracy: 0.6221\n",
      "Epoch 551/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.8383 - val_loss: 0.9351 - val_accuracy: 0.6050\n",
      "Epoch 552/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8488 - val_loss: 0.8776 - val_accuracy: 0.6240\n",
      "Epoch 553/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8192 - val_loss: 0.9525 - val_accuracy: 0.6240\n",
      "Epoch 554/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3601 - accuracy: 0.8368 - val_loss: 0.9203 - val_accuracy: 0.5992\n",
      "Epoch 555/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8392 - val_loss: 0.9382 - val_accuracy: 0.5992\n",
      "Epoch 556/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8244 - val_loss: 0.8819 - val_accuracy: 0.6164\n",
      "Epoch 557/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3572 - accuracy: 0.8416 - val_loss: 0.8748 - val_accuracy: 0.6011\n",
      "Epoch 558/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.8492 - val_loss: 0.9318 - val_accuracy: 0.6145\n",
      "Epoch 559/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8440 - val_loss: 0.8658 - val_accuracy: 0.6183\n",
      "Epoch 560/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8502 - val_loss: 0.8930 - val_accuracy: 0.6107\n",
      "Epoch 561/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8416 - val_loss: 0.8876 - val_accuracy: 0.6221\n",
      "Epoch 562/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8516 - val_loss: 0.9041 - val_accuracy: 0.6355\n",
      "Epoch 563/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3396 - accuracy: 0.8430 - val_loss: 0.9115 - val_accuracy: 0.5935\n",
      "Epoch 564/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3348 - accuracy: 0.8531 - val_loss: 0.9391 - val_accuracy: 0.6050\n",
      "Epoch 565/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8492 - val_loss: 0.8683 - val_accuracy: 0.6202\n",
      "Epoch 566/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.8421 - val_loss: 0.8873 - val_accuracy: 0.6164\n",
      "Epoch 567/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3305 - accuracy: 0.8593 - val_loss: 0.9030 - val_accuracy: 0.6240\n",
      "Epoch 568/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8516 - val_loss: 0.9051 - val_accuracy: 0.6260\n",
      "Epoch 569/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3366 - accuracy: 0.8550 - val_loss: 0.8969 - val_accuracy: 0.6393\n",
      "Epoch 570/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3570 - accuracy: 0.8340 - val_loss: 0.9057 - val_accuracy: 0.6317\n",
      "Epoch 571/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8531 - val_loss: 0.8783 - val_accuracy: 0.6279\n",
      "Epoch 572/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8392 - val_loss: 0.9155 - val_accuracy: 0.6183\n",
      "Epoch 573/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8321 - val_loss: 0.9238 - val_accuracy: 0.6164\n",
      "Epoch 574/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8502 - val_loss: 0.9215 - val_accuracy: 0.6031\n",
      "Epoch 575/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.8383 - val_loss: 0.9042 - val_accuracy: 0.6393\n",
      "Epoch 576/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8483 - val_loss: 0.8978 - val_accuracy: 0.6164\n",
      "Epoch 577/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3263 - accuracy: 0.8616 - val_loss: 0.9869 - val_accuracy: 0.6069\n",
      "Epoch 578/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3224 - accuracy: 0.8516 - val_loss: 0.9998 - val_accuracy: 0.5859\n",
      "Epoch 579/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.8626 - val_loss: 0.9636 - val_accuracy: 0.6164\n",
      "Epoch 580/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3474 - accuracy: 0.8454 - val_loss: 1.0635 - val_accuracy: 0.5802\n",
      "Epoch 581/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8435 - val_loss: 1.0566 - val_accuracy: 0.5553\n",
      "Epoch 582/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.8435 - val_loss: 0.9828 - val_accuracy: 0.6336\n",
      "Epoch 583/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3396 - accuracy: 0.8430 - val_loss: 1.0179 - val_accuracy: 0.6031\n",
      "Epoch 584/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3285 - accuracy: 0.8621 - val_loss: 0.9388 - val_accuracy: 0.6050\n",
      "Epoch 585/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8597 - val_loss: 0.9858 - val_accuracy: 0.5992\n",
      "Epoch 586/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3252 - accuracy: 0.8526 - val_loss: 0.9755 - val_accuracy: 0.6164\n",
      "Epoch 587/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.8488 - val_loss: 1.0286 - val_accuracy: 0.6221\n",
      "Epoch 588/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3214 - accuracy: 0.8593 - val_loss: 0.9270 - val_accuracy: 0.5973\n",
      "Epoch 589/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.8593 - val_loss: 1.0378 - val_accuracy: 0.6107\n",
      "Epoch 590/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8454 - val_loss: 0.8991 - val_accuracy: 0.5821\n",
      "Epoch 591/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3207 - accuracy: 0.8621 - val_loss: 0.8984 - val_accuracy: 0.6317\n",
      "Epoch 592/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3206 - accuracy: 0.8597 - val_loss: 0.9372 - val_accuracy: 0.6317\n",
      "Epoch 593/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8550 - val_loss: 0.9499 - val_accuracy: 0.6011\n",
      "Epoch 594/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8454 - val_loss: 1.0149 - val_accuracy: 0.6126\n",
      "Epoch 595/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8573 - val_loss: 0.9112 - val_accuracy: 0.6145\n",
      "Epoch 596/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8449 - val_loss: 0.9251 - val_accuracy: 0.5973\n",
      "Epoch 597/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3061 - accuracy: 0.8788 - val_loss: 0.9433 - val_accuracy: 0.6317\n",
      "Epoch 598/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3656 - accuracy: 0.8321 - val_loss: 0.9740 - val_accuracy: 0.6183\n",
      "Epoch 599/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8344 - val_loss: 0.9861 - val_accuracy: 0.6069\n",
      "Epoch 600/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8502 - val_loss: 0.9529 - val_accuracy: 0.6145\n",
      "Epoch 601/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.8607 - val_loss: 0.9327 - val_accuracy: 0.6336\n",
      "Epoch 602/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3223 - accuracy: 0.8602 - val_loss: 2.2742 - val_accuracy: 0.5935\n",
      "Epoch 603/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8502 - val_loss: 0.9710 - val_accuracy: 0.6107\n",
      "Epoch 604/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3318 - accuracy: 0.8516 - val_loss: 0.9241 - val_accuracy: 0.6011\n",
      "Epoch 605/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8531 - val_loss: 0.9563 - val_accuracy: 0.6240\n",
      "Epoch 606/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3331 - accuracy: 0.8511 - val_loss: 1.0170 - val_accuracy: 0.6050\n",
      "Epoch 607/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8578 - val_loss: 0.9830 - val_accuracy: 0.6145\n",
      "Epoch 608/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.8483 - val_loss: 0.9662 - val_accuracy: 0.6202\n",
      "Epoch 609/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8550 - val_loss: 0.9371 - val_accuracy: 0.6221\n",
      "Epoch 610/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3239 - accuracy: 0.8583 - val_loss: 0.9222 - val_accuracy: 0.6088\n",
      "Epoch 611/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3115 - accuracy: 0.8678 - val_loss: 0.9286 - val_accuracy: 0.6183\n",
      "Epoch 612/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3301 - accuracy: 0.8521 - val_loss: 0.9483 - val_accuracy: 0.6374\n",
      "Epoch 613/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3294 - accuracy: 0.8583 - val_loss: 0.9681 - val_accuracy: 0.6126\n",
      "Epoch 614/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3123 - accuracy: 0.8659 - val_loss: 1.0008 - val_accuracy: 0.5840\n",
      "Epoch 615/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8459 - val_loss: 1.0080 - val_accuracy: 0.6202\n",
      "Epoch 616/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.8554 - val_loss: 0.9818 - val_accuracy: 0.6107\n",
      "Epoch 617/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3281 - accuracy: 0.8531 - val_loss: 0.9815 - val_accuracy: 0.6202\n",
      "Epoch 618/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3227 - accuracy: 0.8559 - val_loss: 1.0753 - val_accuracy: 0.5935\n",
      "Epoch 619/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8459 - val_loss: 1.0163 - val_accuracy: 0.5859\n",
      "Epoch 620/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.8449 - val_loss: 0.9566 - val_accuracy: 0.6260\n",
      "Epoch 621/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3061 - accuracy: 0.8712 - val_loss: 0.9430 - val_accuracy: 0.6069\n",
      "Epoch 622/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3198 - accuracy: 0.8607 - val_loss: 0.9466 - val_accuracy: 0.6336\n",
      "Epoch 623/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3181 - accuracy: 0.8626 - val_loss: 0.9618 - val_accuracy: 0.6088\n",
      "Epoch 624/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8263 - val_loss: 1.0095 - val_accuracy: 0.6107\n",
      "Epoch 625/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3315 - accuracy: 0.8569 - val_loss: 0.9711 - val_accuracy: 0.6050\n",
      "Epoch 626/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8526 - val_loss: 0.9561 - val_accuracy: 0.6145\n",
      "Epoch 627/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3062 - accuracy: 0.8631 - val_loss: 0.9227 - val_accuracy: 0.6355\n",
      "Epoch 628/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3071 - accuracy: 0.8693 - val_loss: 1.1624 - val_accuracy: 0.6221\n",
      "Epoch 629/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.8497 - val_loss: 1.0400 - val_accuracy: 0.5916\n",
      "Epoch 630/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.8488 - val_loss: 0.9704 - val_accuracy: 0.6240\n",
      "Epoch 631/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2972 - accuracy: 0.8712 - val_loss: 0.9939 - val_accuracy: 0.6126\n",
      "Epoch 632/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3300 - accuracy: 0.8559 - val_loss: 0.9925 - val_accuracy: 0.5878\n",
      "Epoch 633/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3067 - accuracy: 0.8707 - val_loss: 0.9929 - val_accuracy: 0.6126\n",
      "Epoch 634/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8659 - val_loss: 0.9690 - val_accuracy: 0.6050\n",
      "Epoch 635/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.8492 - val_loss: 0.9837 - val_accuracy: 0.6183\n",
      "Epoch 636/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8440 - val_loss: 1.0416 - val_accuracy: 0.6260\n",
      "Epoch 637/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3062 - accuracy: 0.8655 - val_loss: 1.0180 - val_accuracy: 0.6202\n",
      "Epoch 638/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8740 - val_loss: 0.9891 - val_accuracy: 0.6183\n",
      "Epoch 639/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3244 - accuracy: 0.8635 - val_loss: 0.9999 - val_accuracy: 0.6069\n",
      "Epoch 640/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.8707 - val_loss: 0.9627 - val_accuracy: 0.5935\n",
      "Epoch 641/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3251 - accuracy: 0.8492 - val_loss: 1.0938 - val_accuracy: 0.6355\n",
      "Epoch 642/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8445 - val_loss: 0.9491 - val_accuracy: 0.6088\n",
      "Epoch 643/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8669 - val_loss: 1.0382 - val_accuracy: 0.5859\n",
      "Epoch 644/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3056 - accuracy: 0.8659 - val_loss: 1.0162 - val_accuracy: 0.6260\n",
      "Epoch 645/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3042 - accuracy: 0.8750 - val_loss: 1.3047 - val_accuracy: 0.6260\n",
      "Epoch 646/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3056 - accuracy: 0.8712 - val_loss: 0.9697 - val_accuracy: 0.6202\n",
      "Epoch 647/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.3127 - accuracy: 0.8645 - val_loss: 0.9768 - val_accuracy: 0.6393\n",
      "Epoch 648/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3398 - accuracy: 0.8383 - val_loss: 1.0049 - val_accuracy: 0.6050\n",
      "Epoch 649/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3026 - accuracy: 0.8612 - val_loss: 0.9975 - val_accuracy: 0.6145\n",
      "Epoch 650/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3258 - accuracy: 0.8616 - val_loss: 1.5635 - val_accuracy: 0.5363\n",
      "Epoch 651/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3255 - accuracy: 0.8526 - val_loss: 1.0040 - val_accuracy: 0.6145\n",
      "Epoch 652/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2974 - accuracy: 0.8721 - val_loss: 1.0492 - val_accuracy: 0.5935\n",
      "Epoch 653/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2893 - accuracy: 0.8774 - val_loss: 0.9808 - val_accuracy: 0.6088\n",
      "Epoch 654/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.8655 - val_loss: 1.0287 - val_accuracy: 0.6260\n",
      "Epoch 655/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3110 - accuracy: 0.8607 - val_loss: 0.9993 - val_accuracy: 0.6145\n",
      "Epoch 656/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2851 - accuracy: 0.8745 - val_loss: 1.0493 - val_accuracy: 0.5973\n",
      "Epoch 657/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3281 - accuracy: 0.8640 - val_loss: 0.9891 - val_accuracy: 0.6183\n",
      "Epoch 658/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2875 - accuracy: 0.8779 - val_loss: 1.0289 - val_accuracy: 0.6202\n",
      "Epoch 659/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.8760 - val_loss: 1.0480 - val_accuracy: 0.6088\n",
      "Epoch 660/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3234 - accuracy: 0.8554 - val_loss: 1.0256 - val_accuracy: 0.6412\n",
      "Epoch 661/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2987 - accuracy: 0.8664 - val_loss: 1.0039 - val_accuracy: 0.6145\n",
      "Epoch 662/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3165 - accuracy: 0.8583 - val_loss: 1.0170 - val_accuracy: 0.5954\n",
      "Epoch 663/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.8569 - val_loss: 0.9932 - val_accuracy: 0.6088\n",
      "Epoch 664/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3061 - accuracy: 0.8726 - val_loss: 1.0765 - val_accuracy: 0.5897\n",
      "Epoch 665/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2794 - accuracy: 0.8874 - val_loss: 0.9795 - val_accuracy: 0.6107\n",
      "Epoch 666/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3181 - accuracy: 0.8635 - val_loss: 1.0312 - val_accuracy: 0.6221\n",
      "Epoch 667/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3014 - accuracy: 0.8635 - val_loss: 1.1873 - val_accuracy: 0.5592\n",
      "Epoch 668/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3210 - accuracy: 0.8593 - val_loss: 1.0100 - val_accuracy: 0.6202\n",
      "Epoch 669/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2929 - accuracy: 0.8783 - val_loss: 1.0713 - val_accuracy: 0.5897\n",
      "Epoch 670/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3079 - accuracy: 0.8640 - val_loss: 0.9741 - val_accuracy: 0.6298\n",
      "Epoch 671/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8626 - val_loss: 1.1014 - val_accuracy: 0.5992\n",
      "Epoch 672/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.3358 - accuracy: 0.8578 - val_loss: 1.1109 - val_accuracy: 0.5954\n",
      "Epoch 673/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.8616 - val_loss: 1.0690 - val_accuracy: 0.6260\n",
      "Epoch 674/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3015 - accuracy: 0.8669 - val_loss: 1.0412 - val_accuracy: 0.6088\n",
      "Epoch 675/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.8488 - val_loss: 1.1176 - val_accuracy: 0.6298\n",
      "Epoch 676/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2743 - accuracy: 0.8865 - val_loss: 1.0300 - val_accuracy: 0.6164\n",
      "Epoch 677/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.8535 - val_loss: 1.0700 - val_accuracy: 0.6031\n",
      "Epoch 678/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.8531 - val_loss: 1.0384 - val_accuracy: 0.6279\n",
      "Epoch 679/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3095 - accuracy: 0.8645 - val_loss: 1.1201 - val_accuracy: 0.6202\n",
      "Epoch 680/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2967 - accuracy: 0.8798 - val_loss: 1.0355 - val_accuracy: 0.6145\n",
      "Epoch 681/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3099 - accuracy: 0.8664 - val_loss: 1.0106 - val_accuracy: 0.6183\n",
      "Epoch 682/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2937 - accuracy: 0.8702 - val_loss: 1.0533 - val_accuracy: 0.5897\n",
      "Epoch 683/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2876 - accuracy: 0.8764 - val_loss: 1.0300 - val_accuracy: 0.5916\n",
      "Epoch 684/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.8798 - val_loss: 1.0073 - val_accuracy: 0.6088\n",
      "Epoch 685/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2904 - accuracy: 0.8669 - val_loss: 1.0193 - val_accuracy: 0.6450\n",
      "Epoch 686/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8655 - val_loss: 1.0482 - val_accuracy: 0.5954\n",
      "Epoch 687/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3006 - accuracy: 0.8774 - val_loss: 1.0784 - val_accuracy: 0.6050\n",
      "Epoch 688/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2977 - accuracy: 0.8688 - val_loss: 1.0164 - val_accuracy: 0.5935\n",
      "Epoch 689/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2708 - accuracy: 0.8922 - val_loss: 1.0233 - val_accuracy: 0.6088\n",
      "Epoch 690/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2976 - accuracy: 0.8707 - val_loss: 1.0011 - val_accuracy: 0.6031\n",
      "Epoch 691/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3077 - accuracy: 0.8707 - val_loss: 1.0552 - val_accuracy: 0.5878\n",
      "Epoch 692/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2987 - accuracy: 0.8698 - val_loss: 1.0680 - val_accuracy: 0.6202\n",
      "Epoch 693/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2899 - accuracy: 0.8750 - val_loss: 1.1173 - val_accuracy: 0.6011\n",
      "Epoch 694/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2753 - accuracy: 0.8817 - val_loss: 1.0351 - val_accuracy: 0.6240\n",
      "Epoch 695/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.8645 - val_loss: 1.1029 - val_accuracy: 0.6107\n",
      "Epoch 696/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3227 - accuracy: 0.8669 - val_loss: 1.0729 - val_accuracy: 0.6221\n",
      "Epoch 697/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2805 - accuracy: 0.8726 - val_loss: 1.0413 - val_accuracy: 0.6164\n",
      "Epoch 698/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2976 - accuracy: 0.8693 - val_loss: 1.1212 - val_accuracy: 0.6240\n",
      "Epoch 699/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2958 - accuracy: 0.8678 - val_loss: 1.0567 - val_accuracy: 0.6050\n",
      "Epoch 700/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3398 - accuracy: 0.8545 - val_loss: 1.0621 - val_accuracy: 0.5954\n",
      "Epoch 701/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3032 - accuracy: 0.8602 - val_loss: 1.0920 - val_accuracy: 0.6069\n",
      "Epoch 702/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2682 - accuracy: 0.8822 - val_loss: 1.0542 - val_accuracy: 0.6317\n",
      "Epoch 703/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2828 - accuracy: 0.8740 - val_loss: 1.0564 - val_accuracy: 0.6240\n",
      "Epoch 704/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2734 - accuracy: 0.8831 - val_loss: 1.0497 - val_accuracy: 0.6069\n",
      "Epoch 705/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2914 - accuracy: 0.8707 - val_loss: 1.0821 - val_accuracy: 0.6088\n",
      "Epoch 706/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2856 - accuracy: 0.8769 - val_loss: 1.2193 - val_accuracy: 0.5534\n",
      "Epoch 707/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2982 - accuracy: 0.8822 - val_loss: 1.2432 - val_accuracy: 0.6126\n",
      "Epoch 708/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2789 - accuracy: 0.8831 - val_loss: 1.0334 - val_accuracy: 0.5935\n",
      "Epoch 709/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2841 - accuracy: 0.8822 - val_loss: 1.0930 - val_accuracy: 0.6050\n",
      "Epoch 710/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2720 - accuracy: 0.8836 - val_loss: 1.0526 - val_accuracy: 0.5878\n",
      "Epoch 711/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2730 - accuracy: 0.8893 - val_loss: 1.1620 - val_accuracy: 0.6126\n",
      "Epoch 712/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2912 - accuracy: 0.8726 - val_loss: 1.1282 - val_accuracy: 0.5992\n",
      "Epoch 713/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2778 - accuracy: 0.8817 - val_loss: 1.1016 - val_accuracy: 0.5744\n",
      "Epoch 714/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.3120 - accuracy: 0.8683 - val_loss: 1.1321 - val_accuracy: 0.5821\n",
      "Epoch 715/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3005 - accuracy: 0.8721 - val_loss: 1.0957 - val_accuracy: 0.5897\n",
      "Epoch 716/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3041 - accuracy: 0.8645 - val_loss: 1.0694 - val_accuracy: 0.6279\n",
      "Epoch 717/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2759 - accuracy: 0.8869 - val_loss: 1.6217 - val_accuracy: 0.5229\n",
      "Epoch 718/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2781 - accuracy: 0.8807 - val_loss: 1.0675 - val_accuracy: 0.5954\n",
      "Epoch 719/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2918 - accuracy: 0.8707 - val_loss: 1.1925 - val_accuracy: 0.6107\n",
      "Epoch 720/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2595 - accuracy: 0.8874 - val_loss: 1.0554 - val_accuracy: 0.6183\n",
      "Epoch 721/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2787 - accuracy: 0.8798 - val_loss: 1.1697 - val_accuracy: 0.6107\n",
      "Epoch 722/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2647 - accuracy: 0.8950 - val_loss: 1.1426 - val_accuracy: 0.5630\n",
      "Epoch 723/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3045 - accuracy: 0.8612 - val_loss: 1.1086 - val_accuracy: 0.6164\n",
      "Epoch 724/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3112 - accuracy: 0.8645 - val_loss: 1.0348 - val_accuracy: 0.6145\n",
      "Epoch 725/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2982 - accuracy: 0.8626 - val_loss: 1.0597 - val_accuracy: 0.6164\n",
      "Epoch 726/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2616 - accuracy: 0.8879 - val_loss: 1.1090 - val_accuracy: 0.6145\n",
      "Epoch 727/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2460 - accuracy: 0.9003 - val_loss: 1.0614 - val_accuracy: 0.5973\n",
      "Epoch 728/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3344 - accuracy: 0.8507 - val_loss: 1.1159 - val_accuracy: 0.6069\n",
      "Epoch 729/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2775 - accuracy: 0.8836 - val_loss: 1.0768 - val_accuracy: 0.6107\n",
      "Epoch 730/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2498 - accuracy: 0.8974 - val_loss: 1.1529 - val_accuracy: 0.5840\n",
      "Epoch 731/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2605 - accuracy: 0.8950 - val_loss: 1.3125 - val_accuracy: 0.5515\n",
      "Epoch 732/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.8760 - val_loss: 1.1834 - val_accuracy: 0.6069\n",
      "Epoch 733/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.8788 - val_loss: 1.2085 - val_accuracy: 0.6031\n",
      "Epoch 734/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2521 - accuracy: 0.8922 - val_loss: 1.0850 - val_accuracy: 0.6107\n",
      "Epoch 735/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2495 - accuracy: 0.8960 - val_loss: 1.1434 - val_accuracy: 0.6069\n",
      "Epoch 736/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2496 - accuracy: 0.8922 - val_loss: 1.1509 - val_accuracy: 0.6260\n",
      "Epoch 737/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2651 - accuracy: 0.8865 - val_loss: 1.1371 - val_accuracy: 0.6069\n",
      "Epoch 738/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2595 - accuracy: 0.8927 - val_loss: 1.0835 - val_accuracy: 0.6126\n",
      "Epoch 739/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2595 - accuracy: 0.8979 - val_loss: 1.0663 - val_accuracy: 0.6107\n",
      "Epoch 740/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.8240 - val_loss: 1.0701 - val_accuracy: 0.6260\n",
      "Epoch 741/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2940 - accuracy: 0.8764 - val_loss: 1.1177 - val_accuracy: 0.6298\n",
      "Epoch 742/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2781 - accuracy: 0.8845 - val_loss: 1.1371 - val_accuracy: 0.6336\n",
      "Epoch 743/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2867 - accuracy: 0.8783 - val_loss: 1.0944 - val_accuracy: 0.5897\n",
      "Epoch 744/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2808 - accuracy: 0.8779 - val_loss: 1.4117 - val_accuracy: 0.5668\n",
      "Epoch 745/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.8869 - val_loss: 1.1153 - val_accuracy: 0.6031\n",
      "Epoch 746/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8626 - val_loss: 1.2766 - val_accuracy: 0.6011\n",
      "Epoch 747/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3004 - accuracy: 0.8745 - val_loss: 1.1662 - val_accuracy: 0.5954\n",
      "Epoch 748/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.8917 - val_loss: 1.1960 - val_accuracy: 0.6050\n",
      "Epoch 749/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2918 - accuracy: 0.8779 - val_loss: 1.1009 - val_accuracy: 0.6050\n",
      "Epoch 750/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2586 - accuracy: 0.8912 - val_loss: 1.1222 - val_accuracy: 0.6279\n",
      "Epoch 751/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2478 - accuracy: 0.8984 - val_loss: 1.2201 - val_accuracy: 0.6145\n",
      "Epoch 752/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2685 - accuracy: 0.8855 - val_loss: 1.2251 - val_accuracy: 0.5802\n",
      "Epoch 753/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2867 - accuracy: 0.8760 - val_loss: 1.1199 - val_accuracy: 0.6221\n",
      "Epoch 754/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2973 - accuracy: 0.8645 - val_loss: 1.4401 - val_accuracy: 0.6069\n",
      "Epoch 755/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.8688 - val_loss: 1.1551 - val_accuracy: 0.6412\n",
      "Epoch 756/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2430 - accuracy: 0.8993 - val_loss: 1.0916 - val_accuracy: 0.6031\n",
      "Epoch 757/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2836 - accuracy: 0.8774 - val_loss: 1.2799 - val_accuracy: 0.5821\n",
      "Epoch 758/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2668 - accuracy: 0.8879 - val_loss: 1.2824 - val_accuracy: 0.6202\n",
      "Epoch 759/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2534 - accuracy: 0.8989 - val_loss: 1.1079 - val_accuracy: 0.6298\n",
      "Epoch 760/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2655 - accuracy: 0.8793 - val_loss: 1.2058 - val_accuracy: 0.6088\n",
      "Epoch 761/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2618 - accuracy: 0.8893 - val_loss: 1.1367 - val_accuracy: 0.6050\n",
      "Epoch 762/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2591 - accuracy: 0.8946 - val_loss: 1.1261 - val_accuracy: 0.6183\n",
      "Epoch 763/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2813 - accuracy: 0.8740 - val_loss: 1.1172 - val_accuracy: 0.6011\n",
      "Epoch 764/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2717 - accuracy: 0.8888 - val_loss: 1.1165 - val_accuracy: 0.6260\n",
      "Epoch 765/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.9051 - val_loss: 1.1409 - val_accuracy: 0.6202\n",
      "Epoch 766/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2522 - accuracy: 0.9003 - val_loss: 1.2245 - val_accuracy: 0.5897\n",
      "Epoch 767/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2921 - accuracy: 0.8736 - val_loss: 1.1916 - val_accuracy: 0.6202\n",
      "Epoch 768/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2532 - accuracy: 0.8989 - val_loss: 1.1684 - val_accuracy: 0.6107\n",
      "Epoch 769/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3014 - accuracy: 0.8769 - val_loss: 1.1394 - val_accuracy: 0.5992\n",
      "Epoch 770/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2635 - accuracy: 0.8869 - val_loss: 1.2813 - val_accuracy: 0.6069\n",
      "Epoch 771/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2425 - accuracy: 0.9017 - val_loss: 1.1441 - val_accuracy: 0.6164\n",
      "Epoch 772/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2907 - accuracy: 0.8798 - val_loss: 1.2189 - val_accuracy: 0.5802\n",
      "Epoch 773/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2713 - accuracy: 0.8855 - val_loss: 1.1763 - val_accuracy: 0.5954\n",
      "Epoch 774/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2815 - accuracy: 0.8831 - val_loss: 1.1618 - val_accuracy: 0.5992\n",
      "Epoch 775/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2447 - accuracy: 0.8941 - val_loss: 1.1924 - val_accuracy: 0.5859\n",
      "Epoch 776/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2401 - accuracy: 0.8946 - val_loss: 1.1666 - val_accuracy: 0.6202\n",
      "Epoch 777/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2725 - accuracy: 0.8888 - val_loss: 1.2048 - val_accuracy: 0.6260\n",
      "Epoch 778/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2594 - accuracy: 0.8969 - val_loss: 1.2481 - val_accuracy: 0.6031\n",
      "Epoch 779/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.2533 - accuracy: 0.8955 - val_loss: 1.1800 - val_accuracy: 0.5935\n",
      "Epoch 780/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2463 - accuracy: 0.9055 - val_loss: 1.2179 - val_accuracy: 0.6126\n",
      "Epoch 781/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2489 - accuracy: 0.9036 - val_loss: 1.1847 - val_accuracy: 0.6164\n",
      "Epoch 782/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.2449 - accuracy: 0.8969 - val_loss: 1.3542 - val_accuracy: 0.6088\n",
      "Epoch 783/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.2361 - accuracy: 0.9041 - val_loss: 1.1353 - val_accuracy: 0.6069\n",
      "Epoch 784/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.2686 - accuracy: 0.8855 - val_loss: 1.1980 - val_accuracy: 0.6088\n",
      "Epoch 785/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2617 - accuracy: 0.8912 - val_loss: 1.1517 - val_accuracy: 0.6279\n",
      "Epoch 786/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2232 - accuracy: 0.9136 - val_loss: 1.1808 - val_accuracy: 0.5916\n",
      "Epoch 787/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2367 - accuracy: 0.8989 - val_loss: 1.1609 - val_accuracy: 0.5916\n",
      "Epoch 788/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8788 - val_loss: 1.5312 - val_accuracy: 0.6298\n",
      "Epoch 789/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2829 - accuracy: 0.8831 - val_loss: 1.1667 - val_accuracy: 0.6183\n",
      "Epoch 790/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3085 - accuracy: 0.8702 - val_loss: 1.1851 - val_accuracy: 0.6126\n",
      "Epoch 791/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2464 - accuracy: 0.8950 - val_loss: 1.1763 - val_accuracy: 0.6145\n",
      "Epoch 792/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2738 - accuracy: 0.8888 - val_loss: 1.1504 - val_accuracy: 0.6183\n",
      "Epoch 793/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.2657 - accuracy: 0.8903 - val_loss: 1.1612 - val_accuracy: 0.6050\n",
      "Epoch 794/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2553 - accuracy: 0.8927 - val_loss: 1.2436 - val_accuracy: 0.6069\n",
      "Epoch 795/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2454 - accuracy: 0.9031 - val_loss: 1.2108 - val_accuracy: 0.6031\n",
      "Epoch 796/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2479 - accuracy: 0.8917 - val_loss: 1.1673 - val_accuracy: 0.6145\n",
      "Epoch 797/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2376 - accuracy: 0.9113 - val_loss: 1.3737 - val_accuracy: 0.5630\n",
      "Epoch 798/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2212 - accuracy: 0.9194 - val_loss: 1.1882 - val_accuracy: 0.5973\n",
      "Epoch 799/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.8965 - val_loss: 1.1661 - val_accuracy: 0.6202\n",
      "Epoch 800/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.2363 - accuracy: 0.9055 - val_loss: 1.1670 - val_accuracy: 0.6069\n",
      "Epoch 801/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2281 - accuracy: 0.9051 - val_loss: 1.2264 - val_accuracy: 0.6088\n",
      "Epoch 802/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8383 - val_loss: 1.2442 - val_accuracy: 0.5916\n",
      "Epoch 803/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2738 - accuracy: 0.8817 - val_loss: 1.5733 - val_accuracy: 0.6298\n",
      "Epoch 804/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2754 - accuracy: 0.8817 - val_loss: 1.6168 - val_accuracy: 0.5954\n",
      "Epoch 805/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2768 - accuracy: 0.8874 - val_loss: 1.2479 - val_accuracy: 0.5935\n",
      "Epoch 806/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2492 - accuracy: 0.9027 - val_loss: 1.2104 - val_accuracy: 0.6164\n",
      "Epoch 807/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2766 - accuracy: 0.8841 - val_loss: 1.1983 - val_accuracy: 0.5954\n",
      "Epoch 808/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2294 - accuracy: 0.9079 - val_loss: 1.6069 - val_accuracy: 0.5324\n",
      "Epoch 809/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2442 - accuracy: 0.9027 - val_loss: 1.2301 - val_accuracy: 0.6279\n",
      "Epoch 810/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2277 - accuracy: 0.9070 - val_loss: 1.2126 - val_accuracy: 0.6126\n",
      "Epoch 811/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2931 - accuracy: 0.8760 - val_loss: 1.4259 - val_accuracy: 0.6107\n",
      "Epoch 812/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2432 - accuracy: 0.9074 - val_loss: 1.1890 - val_accuracy: 0.6202\n",
      "Epoch 813/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8650 - val_loss: 1.3050 - val_accuracy: 0.6126\n",
      "Epoch 814/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2324 - accuracy: 0.9055 - val_loss: 1.1500 - val_accuracy: 0.6126\n",
      "Epoch 815/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2645 - accuracy: 0.8960 - val_loss: 1.2435 - val_accuracy: 0.6050\n",
      "Epoch 816/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2337 - accuracy: 0.9065 - val_loss: 1.2268 - val_accuracy: 0.5954\n",
      "Epoch 817/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2122 - accuracy: 0.9175 - val_loss: 1.1735 - val_accuracy: 0.5992\n",
      "Epoch 818/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2163 - accuracy: 0.9165 - val_loss: 1.1868 - val_accuracy: 0.5916\n",
      "Epoch 819/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2256 - accuracy: 0.9103 - val_loss: 1.1431 - val_accuracy: 0.6183\n",
      "Epoch 820/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2264 - accuracy: 0.9089 - val_loss: 1.2441 - val_accuracy: 0.6260\n",
      "Epoch 821/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.2290 - accuracy: 0.9074 - val_loss: 1.2762 - val_accuracy: 0.6088\n",
      "Epoch 822/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2206 - accuracy: 0.9165 - val_loss: 1.2017 - val_accuracy: 0.6145\n",
      "Epoch 823/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2502 - accuracy: 0.8860 - val_loss: 1.2055 - val_accuracy: 0.6145\n",
      "Epoch 824/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3283 - accuracy: 0.8736 - val_loss: 1.2958 - val_accuracy: 0.6107\n",
      "Epoch 825/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2251 - accuracy: 0.9074 - val_loss: 1.2987 - val_accuracy: 0.5802\n",
      "Epoch 826/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2319 - accuracy: 0.9027 - val_loss: 1.2040 - val_accuracy: 0.6069\n",
      "Epoch 827/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2670 - accuracy: 0.8912 - val_loss: 1.2589 - val_accuracy: 0.6107\n",
      "Epoch 828/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2223 - accuracy: 0.9098 - val_loss: 1.4361 - val_accuracy: 0.6183\n",
      "Epoch 829/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2373 - accuracy: 0.9074 - val_loss: 1.2119 - val_accuracy: 0.6145\n",
      "Epoch 830/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2180 - accuracy: 0.9079 - val_loss: 1.2441 - val_accuracy: 0.5935\n",
      "Epoch 831/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2242 - accuracy: 0.9070 - val_loss: 1.3634 - val_accuracy: 0.6145\n",
      "Epoch 832/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.2411 - accuracy: 0.9008 - val_loss: 1.2263 - val_accuracy: 0.5935\n",
      "Epoch 833/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2147 - accuracy: 0.9184 - val_loss: 1.2349 - val_accuracy: 0.6279\n",
      "Epoch 834/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.1946 - accuracy: 0.9313 - val_loss: 1.2561 - val_accuracy: 0.5840\n",
      "Epoch 835/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.2237 - accuracy: 0.9132 - val_loss: 1.2140 - val_accuracy: 0.5992\n",
      "Epoch 836/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.2336 - accuracy: 0.9141 - val_loss: 1.3995 - val_accuracy: 0.6164\n",
      "Epoch 837/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2205 - accuracy: 0.9113 - val_loss: 1.3817 - val_accuracy: 0.5840\n",
      "Epoch 838/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.2996 - accuracy: 0.8774 - val_loss: 1.2259 - val_accuracy: 0.6069\n",
      "Epoch 839/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2366 - accuracy: 0.9051 - val_loss: 1.2413 - val_accuracy: 0.6164\n",
      "Epoch 840/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2081 - accuracy: 0.9160 - val_loss: 1.2404 - val_accuracy: 0.6279\n",
      "Epoch 841/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2384 - accuracy: 0.9008 - val_loss: 1.3512 - val_accuracy: 0.5782\n",
      "Epoch 842/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.2064 - accuracy: 0.9218 - val_loss: 1.2434 - val_accuracy: 0.6126\n",
      "Epoch 843/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2404 - accuracy: 0.8950 - val_loss: 1.3033 - val_accuracy: 0.6336\n",
      "Epoch 844/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2264 - accuracy: 0.9036 - val_loss: 1.4516 - val_accuracy: 0.6050\n",
      "Epoch 845/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2229 - accuracy: 0.9117 - val_loss: 1.3299 - val_accuracy: 0.6183\n",
      "Epoch 846/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2204 - accuracy: 0.9170 - val_loss: 1.2700 - val_accuracy: 0.6107\n",
      "Epoch 847/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2005 - accuracy: 0.9213 - val_loss: 1.2230 - val_accuracy: 0.6069\n",
      "Epoch 848/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8731 - val_loss: 1.5436 - val_accuracy: 0.5496\n",
      "Epoch 849/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2134 - accuracy: 0.9146 - val_loss: 1.2614 - val_accuracy: 0.6050\n",
      "Epoch 850/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1972 - accuracy: 0.9213 - val_loss: 1.2464 - val_accuracy: 0.5954\n",
      "Epoch 851/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2484 - accuracy: 0.9003 - val_loss: 1.2358 - val_accuracy: 0.6031\n",
      "Epoch 852/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1988 - accuracy: 0.9241 - val_loss: 1.3826 - val_accuracy: 0.5954\n",
      "Epoch 853/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.2586 - accuracy: 0.8960 - val_loss: 1.3216 - val_accuracy: 0.6088\n",
      "Epoch 854/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.9246 - val_loss: 1.2202 - val_accuracy: 0.5916\n",
      "Epoch 855/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.8817 - val_loss: 1.2775 - val_accuracy: 0.5897\n",
      "Epoch 856/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2199 - accuracy: 0.9094 - val_loss: 1.3187 - val_accuracy: 0.5897\n",
      "Epoch 857/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2601 - accuracy: 0.9046 - val_loss: 1.2475 - val_accuracy: 0.6107\n",
      "Epoch 858/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2960 - accuracy: 0.8831 - val_loss: 1.2374 - val_accuracy: 0.6088\n",
      "Epoch 859/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2150 - accuracy: 0.9156 - val_loss: 1.2175 - val_accuracy: 0.5897\n",
      "Epoch 860/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2484 - accuracy: 0.8960 - val_loss: 1.7106 - val_accuracy: 0.5305\n",
      "Epoch 861/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2565 - accuracy: 0.8903 - val_loss: 1.3102 - val_accuracy: 0.6221\n",
      "Epoch 862/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1797 - accuracy: 0.9370 - val_loss: 1.3155 - val_accuracy: 0.5821\n",
      "Epoch 863/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2079 - accuracy: 0.9165 - val_loss: 1.2488 - val_accuracy: 0.6279\n",
      "Epoch 864/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1998 - accuracy: 0.9289 - val_loss: 1.2428 - val_accuracy: 0.6031\n",
      "Epoch 865/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2016 - accuracy: 0.9237 - val_loss: 1.3258 - val_accuracy: 0.5821\n",
      "Epoch 866/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1934 - accuracy: 0.9275 - val_loss: 1.3469 - val_accuracy: 0.5973\n",
      "Epoch 867/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2135 - accuracy: 0.9251 - val_loss: 1.2569 - val_accuracy: 0.6011\n",
      "Epoch 868/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2152 - accuracy: 0.9108 - val_loss: 1.2869 - val_accuracy: 0.6145\n",
      "Epoch 869/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2204 - accuracy: 0.9094 - val_loss: 1.2969 - val_accuracy: 0.6031\n",
      "Epoch 870/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2005 - accuracy: 0.9232 - val_loss: 1.3663 - val_accuracy: 0.6011\n",
      "Epoch 871/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2256 - accuracy: 0.9108 - val_loss: 1.4993 - val_accuracy: 0.6221\n",
      "Epoch 872/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2259 - accuracy: 0.9065 - val_loss: 1.3185 - val_accuracy: 0.6279\n",
      "Epoch 873/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2265 - accuracy: 0.9022 - val_loss: 1.3390 - val_accuracy: 0.5992\n",
      "Epoch 874/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1852 - accuracy: 0.9299 - val_loss: 1.2273 - val_accuracy: 0.6088\n",
      "Epoch 875/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2294 - accuracy: 0.9141 - val_loss: 1.3519 - val_accuracy: 0.5897\n",
      "Epoch 876/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1824 - accuracy: 0.9332 - val_loss: 1.3033 - val_accuracy: 0.6011\n",
      "Epoch 877/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2136 - accuracy: 0.9251 - val_loss: 1.3524 - val_accuracy: 0.5725\n",
      "Epoch 878/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2401 - accuracy: 0.9065 - val_loss: 1.3466 - val_accuracy: 0.5840\n",
      "Epoch 879/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2554 - accuracy: 0.9051 - val_loss: 1.3178 - val_accuracy: 0.5954\n",
      "Epoch 880/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2084 - accuracy: 0.9179 - val_loss: 1.3365 - val_accuracy: 0.5782\n",
      "Epoch 881/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2752 - accuracy: 0.8979 - val_loss: 1.3267 - val_accuracy: 0.6126\n",
      "Epoch 882/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2902 - accuracy: 0.8817 - val_loss: 1.2709 - val_accuracy: 0.6145\n",
      "Epoch 883/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1837 - accuracy: 0.9270 - val_loss: 1.3201 - val_accuracy: 0.6183\n",
      "Epoch 884/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1998 - accuracy: 0.9241 - val_loss: 1.3125 - val_accuracy: 0.6164\n",
      "Epoch 885/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1825 - accuracy: 0.9327 - val_loss: 1.2896 - val_accuracy: 0.6011\n",
      "Epoch 886/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8688 - val_loss: 1.3871 - val_accuracy: 0.5954\n",
      "Epoch 887/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1914 - accuracy: 0.9280 - val_loss: 1.2685 - val_accuracy: 0.5973\n",
      "Epoch 888/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2070 - accuracy: 0.9251 - val_loss: 1.6238 - val_accuracy: 0.6145\n",
      "Epoch 889/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2292 - accuracy: 0.9055 - val_loss: 1.2993 - val_accuracy: 0.6298\n",
      "Epoch 890/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2295 - accuracy: 0.9060 - val_loss: 1.2976 - val_accuracy: 0.5935\n",
      "Epoch 891/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1901 - accuracy: 0.9332 - val_loss: 1.3465 - val_accuracy: 0.5973\n",
      "Epoch 892/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8721 - val_loss: 1.8853 - val_accuracy: 0.6107\n",
      "Epoch 893/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2211 - accuracy: 0.9175 - val_loss: 1.3222 - val_accuracy: 0.6183\n",
      "Epoch 894/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1850 - accuracy: 0.9332 - val_loss: 1.3297 - val_accuracy: 0.5916\n",
      "Epoch 895/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1786 - accuracy: 0.9337 - val_loss: 1.3579 - val_accuracy: 0.5840\n",
      "Epoch 896/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2276 - accuracy: 0.9179 - val_loss: 1.2992 - val_accuracy: 0.5859\n",
      "Epoch 897/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1685 - accuracy: 0.9456 - val_loss: 1.6399 - val_accuracy: 0.6145\n",
      "Epoch 898/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1990 - accuracy: 0.9198 - val_loss: 1.2813 - val_accuracy: 0.6107\n",
      "Epoch 899/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2131 - accuracy: 0.9194 - val_loss: 1.3547 - val_accuracy: 0.6221\n",
      "Epoch 900/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1977 - accuracy: 0.9275 - val_loss: 1.3642 - val_accuracy: 0.6050\n",
      "Epoch 901/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2085 - accuracy: 0.9165 - val_loss: 1.3931 - val_accuracy: 0.6126\n",
      "Epoch 902/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1826 - accuracy: 0.9356 - val_loss: 1.2872 - val_accuracy: 0.6126\n",
      "Epoch 903/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2659 - accuracy: 0.8998 - val_loss: 1.3029 - val_accuracy: 0.6031\n",
      "Epoch 904/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1840 - accuracy: 0.9318 - val_loss: 1.3145 - val_accuracy: 0.5706\n",
      "Epoch 905/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2346 - accuracy: 0.9098 - val_loss: 1.6131 - val_accuracy: 0.6050\n",
      "Epoch 906/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2327 - accuracy: 0.9175 - val_loss: 1.3629 - val_accuracy: 0.5973\n",
      "Epoch 907/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1979 - accuracy: 0.9189 - val_loss: 1.3217 - val_accuracy: 0.6183\n",
      "Epoch 908/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1878 - accuracy: 0.9241 - val_loss: 1.4154 - val_accuracy: 0.5821\n",
      "Epoch 909/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1913 - accuracy: 0.9289 - val_loss: 1.3045 - val_accuracy: 0.6183\n",
      "Epoch 910/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1797 - accuracy: 0.9332 - val_loss: 1.4378 - val_accuracy: 0.5878\n",
      "Epoch 911/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1636 - accuracy: 0.9442 - val_loss: 1.4467 - val_accuracy: 0.5802\n",
      "Epoch 912/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2058 - accuracy: 0.9179 - val_loss: 1.4031 - val_accuracy: 0.6240\n",
      "Epoch 913/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1578 - accuracy: 0.9466 - val_loss: 1.3560 - val_accuracy: 0.5916\n",
      "Epoch 914/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2062 - accuracy: 0.9237 - val_loss: 1.3272 - val_accuracy: 0.6145\n",
      "Epoch 915/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2008 - accuracy: 0.9222 - val_loss: 1.3341 - val_accuracy: 0.6202\n",
      "Epoch 916/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1720 - accuracy: 0.9356 - val_loss: 1.4157 - val_accuracy: 0.5782\n",
      "Epoch 917/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2186 - accuracy: 0.9270 - val_loss: 1.4674 - val_accuracy: 0.5840\n",
      "Epoch 918/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2039 - accuracy: 0.9194 - val_loss: 1.4115 - val_accuracy: 0.6107\n",
      "Epoch 919/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1907 - accuracy: 0.9318 - val_loss: 1.3811 - val_accuracy: 0.6164\n",
      "Epoch 920/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2780 - accuracy: 0.8860 - val_loss: 1.9916 - val_accuracy: 0.5305\n",
      "Epoch 921/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2350 - accuracy: 0.9203 - val_loss: 1.4397 - val_accuracy: 0.5763\n",
      "Epoch 922/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2063 - accuracy: 0.9146 - val_loss: 1.3066 - val_accuracy: 0.6107\n",
      "Epoch 923/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1884 - accuracy: 0.9270 - val_loss: 1.3530 - val_accuracy: 0.6260\n",
      "Epoch 924/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1575 - accuracy: 0.9480 - val_loss: 1.4928 - val_accuracy: 0.5744\n",
      "Epoch 925/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1798 - accuracy: 0.9323 - val_loss: 1.8383 - val_accuracy: 0.5382\n",
      "Epoch 926/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9046 - val_loss: 1.4660 - val_accuracy: 0.6088\n",
      "Epoch 927/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2029 - accuracy: 0.9241 - val_loss: 1.3183 - val_accuracy: 0.6011\n",
      "Epoch 928/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2768 - accuracy: 0.8941 - val_loss: 1.9009 - val_accuracy: 0.5344\n",
      "Epoch 929/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.8550 - val_loss: 1.3586 - val_accuracy: 0.6031\n",
      "Epoch 930/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1791 - accuracy: 0.9337 - val_loss: 1.3703 - val_accuracy: 0.6050\n",
      "Epoch 931/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2165 - accuracy: 0.9141 - val_loss: 1.3554 - val_accuracy: 0.5935\n",
      "Epoch 932/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2257 - accuracy: 0.9094 - val_loss: 1.3340 - val_accuracy: 0.5954\n",
      "Epoch 933/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2301 - accuracy: 0.9027 - val_loss: 1.4484 - val_accuracy: 0.5840\n",
      "Epoch 934/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1870 - accuracy: 0.9265 - val_loss: 1.6131 - val_accuracy: 0.6126\n",
      "Epoch 935/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2075 - accuracy: 0.9141 - val_loss: 1.5902 - val_accuracy: 0.6164\n",
      "Epoch 936/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1847 - accuracy: 0.9294 - val_loss: 1.3155 - val_accuracy: 0.6240\n",
      "Epoch 937/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1679 - accuracy: 0.9370 - val_loss: 1.3189 - val_accuracy: 0.5973\n",
      "Epoch 938/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2143 - accuracy: 0.9222 - val_loss: 1.4474 - val_accuracy: 0.6031\n",
      "Epoch 939/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1880 - accuracy: 0.9280 - val_loss: 1.4191 - val_accuracy: 0.6031\n",
      "Epoch 940/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.1496 - accuracy: 0.9513 - val_loss: 1.3828 - val_accuracy: 0.5897\n",
      "Epoch 941/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1484 - accuracy: 0.9547 - val_loss: 1.4260 - val_accuracy: 0.5859\n",
      "Epoch 942/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2091 - accuracy: 0.9218 - val_loss: 1.3644 - val_accuracy: 0.5859\n",
      "Epoch 943/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2397 - accuracy: 0.9175 - val_loss: 1.4175 - val_accuracy: 0.6050\n",
      "Epoch 944/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1415 - accuracy: 0.9585 - val_loss: 1.4655 - val_accuracy: 0.5878\n",
      "Epoch 945/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1565 - accuracy: 0.9418 - val_loss: 1.6785 - val_accuracy: 0.6298\n",
      "Epoch 946/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1514 - accuracy: 0.9499 - val_loss: 1.5929 - val_accuracy: 0.6145\n",
      "Epoch 947/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1811 - accuracy: 0.9399 - val_loss: 1.5697 - val_accuracy: 0.5954\n",
      "Epoch 948/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1626 - accuracy: 0.9418 - val_loss: 1.4549 - val_accuracy: 0.5878\n",
      "Epoch 949/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.8841 - val_loss: 1.7451 - val_accuracy: 0.5573\n",
      "Epoch 950/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2224 - accuracy: 0.9141 - val_loss: 1.4708 - val_accuracy: 0.5992\n",
      "Epoch 951/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1859 - accuracy: 0.9327 - val_loss: 1.4752 - val_accuracy: 0.5706\n",
      "Epoch 952/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1643 - accuracy: 0.9394 - val_loss: 1.3699 - val_accuracy: 0.5859\n",
      "Epoch 953/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1816 - accuracy: 0.9303 - val_loss: 1.4737 - val_accuracy: 0.6240\n",
      "Epoch 954/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2483 - accuracy: 0.9089 - val_loss: 1.4043 - val_accuracy: 0.6221\n",
      "Epoch 955/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1656 - accuracy: 0.9394 - val_loss: 1.6508 - val_accuracy: 0.6164\n",
      "Epoch 956/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1550 - accuracy: 0.9480 - val_loss: 1.5662 - val_accuracy: 0.6221\n",
      "Epoch 957/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1850 - accuracy: 0.9265 - val_loss: 1.3617 - val_accuracy: 0.6240\n",
      "Epoch 958/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1777 - accuracy: 0.9356 - val_loss: 1.3983 - val_accuracy: 0.5973\n",
      "Epoch 959/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1387 - accuracy: 0.9642 - val_loss: 1.3996 - val_accuracy: 0.5954\n",
      "Epoch 960/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1666 - accuracy: 0.9423 - val_loss: 1.4346 - val_accuracy: 0.5954\n",
      "Epoch 961/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.1529 - accuracy: 0.9509 - val_loss: 1.4446 - val_accuracy: 0.5897\n",
      "Epoch 962/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1815 - accuracy: 0.9351 - val_loss: 1.8144 - val_accuracy: 0.6088\n",
      "Epoch 963/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1883 - accuracy: 0.9280 - val_loss: 1.4010 - val_accuracy: 0.5897\n",
      "Epoch 964/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1489 - accuracy: 0.9518 - val_loss: 1.3946 - val_accuracy: 0.5878\n",
      "Epoch 965/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1511 - accuracy: 0.9504 - val_loss: 1.5341 - val_accuracy: 0.5992\n",
      "Epoch 966/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1494 - accuracy: 0.9499 - val_loss: 1.5117 - val_accuracy: 0.5802\n",
      "Epoch 967/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2737 - accuracy: 0.9022 - val_loss: 1.4278 - val_accuracy: 0.5916\n",
      "Epoch 968/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1679 - accuracy: 0.9351 - val_loss: 1.4808 - val_accuracy: 0.5935\n",
      "Epoch 969/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1705 - accuracy: 0.9399 - val_loss: 1.4578 - val_accuracy: 0.5954\n",
      "Epoch 970/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1686 - accuracy: 0.9346 - val_loss: 1.6039 - val_accuracy: 0.5706\n",
      "Epoch 971/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1642 - accuracy: 0.9389 - val_loss: 1.4576 - val_accuracy: 0.5954\n",
      "Epoch 972/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1971 - accuracy: 0.9246 - val_loss: 2.0680 - val_accuracy: 0.6298\n",
      "Epoch 973/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2788 - accuracy: 0.8989 - val_loss: 1.6575 - val_accuracy: 0.6107\n",
      "Epoch 974/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1651 - accuracy: 0.9394 - val_loss: 1.3919 - val_accuracy: 0.6088\n",
      "Epoch 975/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2292 - accuracy: 0.9203 - val_loss: 1.5375 - val_accuracy: 0.5973\n",
      "Epoch 976/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2234 - accuracy: 0.9189 - val_loss: 1.4273 - val_accuracy: 0.5992\n",
      "Epoch 977/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1797 - accuracy: 0.9356 - val_loss: 1.4815 - val_accuracy: 0.5897\n",
      "Epoch 978/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1655 - accuracy: 0.9442 - val_loss: 1.4614 - val_accuracy: 0.5821\n",
      "Epoch 979/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2524 - accuracy: 0.9108 - val_loss: 1.5165 - val_accuracy: 0.6393\n",
      "Epoch 980/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1751 - accuracy: 0.9394 - val_loss: 1.4136 - val_accuracy: 0.5802\n",
      "Epoch 981/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1607 - accuracy: 0.9361 - val_loss: 1.5242 - val_accuracy: 0.5992\n",
      "Epoch 982/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1421 - accuracy: 0.9552 - val_loss: 1.4797 - val_accuracy: 0.6088\n",
      "Epoch 983/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1567 - accuracy: 0.9432 - val_loss: 1.5015 - val_accuracy: 0.5878\n",
      "Epoch 984/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1486 - accuracy: 0.9537 - val_loss: 1.6300 - val_accuracy: 0.6164\n",
      "Epoch 985/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1710 - accuracy: 0.9365 - val_loss: 1.5844 - val_accuracy: 0.6088\n",
      "Epoch 986/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1666 - accuracy: 0.9413 - val_loss: 1.6414 - val_accuracy: 0.6317\n",
      "Epoch 987/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2268 - accuracy: 0.9113 - val_loss: 1.4486 - val_accuracy: 0.5973\n",
      "Epoch 988/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1407 - accuracy: 0.9561 - val_loss: 1.4527 - val_accuracy: 0.5973\n",
      "Epoch 989/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1414 - accuracy: 0.9575 - val_loss: 1.4799 - val_accuracy: 0.5763\n",
      "Epoch 990/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1410 - accuracy: 0.9504 - val_loss: 1.4596 - val_accuracy: 0.5859\n",
      "Epoch 991/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2209 - accuracy: 0.9275 - val_loss: 1.4621 - val_accuracy: 0.6183\n",
      "Epoch 992/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1367 - accuracy: 0.9585 - val_loss: 1.4785 - val_accuracy: 0.5935\n",
      "Epoch 993/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1500 - accuracy: 0.9490 - val_loss: 2.0390 - val_accuracy: 0.5439\n",
      "Epoch 994/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2194 - accuracy: 0.9299 - val_loss: 1.4853 - val_accuracy: 0.5954\n",
      "Epoch 995/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1896 - accuracy: 0.9299 - val_loss: 1.5951 - val_accuracy: 0.5954\n",
      "Epoch 996/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1676 - accuracy: 0.9332 - val_loss: 1.5298 - val_accuracy: 0.6088\n",
      "Epoch 997/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.9451 - val_loss: 1.4793 - val_accuracy: 0.6031\n",
      "Epoch 998/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1331 - accuracy: 0.9590 - val_loss: 1.7198 - val_accuracy: 0.5935\n",
      "Epoch 999/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1637 - accuracy: 0.9418 - val_loss: 1.4721 - val_accuracy: 0.6107\n",
      "Epoch 1000/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1657 - accuracy: 0.9413 - val_loss: 1.5544 - val_accuracy: 0.6126\n"
     ]
    }
   ],
   "source": [
    "history = red.fit(x_train, y_train, epochs=1000, batch_size=30, validation_split=0.2) #entrenamos el modelo con 100 epocas y un tamaÃ±o de lote de 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficamos la pecision de la red con respecto a las epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"ENTRENAMIENTO DE LA RED NURONAL\") #titulo de la grafica\n",
    "plt.xlabel(\"EPOCAS\") #etiqueta del eje x\n",
    "plt.ylabel(\"PRECISION\") #etiqueta del eje y\n",
    "plt.plot(history.history['accuracy'], label='accuracy') #graficamos la exactitud del modelo\n",
    "plt.show() #mostramos la grafica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prediccion = red.predict(x_test) #hacemos la prediccion con el conjunto de prueba\n",
    "y_prediccion = np.round(y_prediccion) #redondeamos los resultados a 0 o 1\n",
    "y_prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step - loss: 1.5727 - accuracy: 0.6067\n",
      "Precision del modelo:  0.6067073170731707\n",
      "Resultado del modelo:  [1.5726515054702759, 0.6067073345184326]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score #importamos la funcion de precision\n",
    "score = accuracy_score(y_test, y_prediccion) #calculamos la precision\n",
    "result = red.evaluate(x_test, y_test) #evaluamos el modelo con el conjunto de prueba\n",
    "print(\"Precision del modelo: \", score) #imprimimos la precision del modelo\n",
    "print(\"Resultado del modelo: \", result) #imprimimos el resultado del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusion:  [[350  62]\n",
      " [153  91]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test, y_prediccion) #matriz de confusion\n",
    "print(\"Matriz de confusion: \", matrix) #imprimimos la matriz de confusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
